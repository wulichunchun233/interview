## 消息队列MQ

鑫课堂项目中的**订单管理模块**、**媒资管理模块**以及**CMS模块**都用到了消息队列。

### 0.RabbitMQ 的工作原理以及工作模式

![23](/Users/wx/project/interview/docs/秘籍/images/23.png)

其中：

- **Broker**：消息队列服务进程，此进程包括两个部分：Exchange 和 Queue，是 RabbitMQ的核心组成部分。
- **Exchange**：消息队列交换机，按一定的规则将消息路由转发到某个队列，对消息进行过虑。
- **Queue**：消息队列，存储消息的队列，消息到达队列并转发给指定的消费方。
- **Producer**：消息生产者，即生产方客户端，生产方客户端将消息发送到MQ。
- **Consumer**：消息消费者，即消费方客户端，接收MQ转发的消息。

其中我们的发送消息的**生产者**通过 RabbitMQ 与接收消息的消费方进行消息通信的流程如下：

1、生产者和 Broker 建立 TCP 连接。

2、生产者和 Broker 建立 Channel(通道)。

3、生产者通过 Channel 将消息发送给 Broker，由Exchange(交换机) 将消息进行转发。

4、Exchange 将消息转发到指定的 Queue(队列)。

而消息的接收方**消费者**获取消息的流程如下：

1、消费者和 Broker 建立 TCP 连接。

2、消费者和 Broker 建立Channel(通道)。

3、消费者监听指定的 Queue。

4、当有消息到达 Queue 时 Broker 默认将消息推送给消费者。

5、消费者接收到消息。

RabbitMQ 共有以下几种工作模式 ：

- Work queues：工作队列模式
- Publish/Subscribe：发布订阅模式
- Routing：路由模式
- Topics：通配符模式
- Header：Header 模式
- RPC：RPC 模式

**工作队列模式** ：多个消费端共同消费同一个队列中的消息。对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。

1、一条消息只会被一个消费者接收；

2、rabbit采用**轮询**的方式将消息是平均发送给消费者的；

3、消费者在处理完某条消息后，才会收到下一条消息。

**发布订阅模式**：每个消费者监听自己的队列。生产者将消息发给 broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息。

**publish/subscribe 与 work queues 有什么区别？**

**相同点**：

两者实现的发布/订阅的效果是一样的，多个消费端监听同一个队列不会重复消费消息，都是通过**轮询**的方式接收消息。

**区别**：

1）work queues 不用定义交换机，而publish/subscribe需要定义交换机。

2）publish/subscribe 的生产方是面向交换机发送消息，work queues的生产方是面向队列发送消息(底层使用默认交换机)。

3）publish/subscribe 需要设置队列和交换机的绑定，work queues不需要设置，实质上work queues会将队列绑定到默认的交换机。

实际工作中建议使用 publish/subscribe，发布订阅模式比工作队列模式更强大，并且发布订阅模式可以指定自己专用的交换机。

**路由模式**：

1、每个消费者监听自己的队列，并且设置 routingkey。

2、生产者将消息发给交换机，由交换机根据 routingkey 来转发消息到指定的队列。

3、routingkey 是决定消息发送到哪个队列的关键。

**Routing 模式和 Publish/subscibe 有啥区别？**

Routing 模式要求队列在绑定交换机时要指定 routingkey，消息会转发到符合 routingkey 的队列。

**通配符模式**：

1、每个消费者监听自己的队列，并且设置带**通配符**的routingkey。

2、生产者将消息发给broker，由交换机根据routingkey来转发消息到指定的队列。

其中，通配符的格式为：

- 符号“#”可以匹配多个词语。
- 符号“*”可以匹配一个词语。

Topic模式更多加强大，它可以实现 Routing、publish/subscirbe 模式的功能。

**header 模式**与 routing 不同的地方在于，header 模式取消 routingkey，使用 header 中的 key/value（键值对）匹配队列。

**RPC 即客户端远程调用服务端**的方法 ，使用 MQ 可以实现 RPC 的异步调用，基于Direct交换机实现，流程如下：

1、客户端即是生产者就是消费者，向 RPC 请求队列发送 RPC 调用消息，同时监听 RPC 响应队列。

2、服务端监听 RPC 请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果。

3、服务端将 RPC 方法的结果发送到 RPC 响应队列。

4、客户端（RPC调用方）监听 RPC 响应队列，接收到RPC调用结果。

### ==1.什么是消息队列？消息队列消息的推送模式？==

**1）消息队列介绍**

我们可以把**消息队列**比作是**一个存放消息的容器**，当我们需要使用消息的时候可以取出消息供自己使用。消息队列是**分布式系统**中重要的组件，使用消息队列主要是为了**通过异步处理提高系统性能和削峰、降低系统耦合性**。

另外，我们知道**队列 Queue** 是一种**先进先出**的数据结构，所以消费消息时也是按照顺序来消费的。

**2）消息队列消息的推送模式**

消息队列支持 **Push/Pull** 两种消息的推送模式。

Push方式：

**优点：**有消息就推给消费者。延迟小,几乎可以做到实时。等等。。。。

**缺点：**Server端接收到消息后，主动把消息推送给Client端，实时性高。对于一个提供队列服务的Server来说，用Push方式主动推送有很多弊端；首先是加大Server端的工作量，进而影响Server的性能，其次Client的处理能力各不相同，Client的状态不受Server控制，如果Client不能及时处理Server推送过来的消息，会造成各种潜在问题。

菠萝科技注：意思是1 加大server(broker)工作量,影响性能。2 有的消费者机器配置好处理能力强,有的配置低处理能力低,但是server推相同数量级消息给消费者，就会导致消费者强的等待,弱的处理效率跟不上,从而导致崩溃。3server资源相比消费者的资源肯定是更宝贵 4总结下就是客户端慢消费(设计到io等耗时操作)时会放大缺点。

Pull方式：

**优点：**对比push优点就是消费者可以根据自己能力拉取消息处理**。。。**

**缺点：**Client端循环地从Server端拉取消息，主动权在Client手里，自己拉取到一定量消息后，处理妥当了再接着取。Pull方式的问题是循环拉取**消息的间隔**不好设定，间隔太短就处在一个“忙等”的状态，浪费资源；每个Pull的时间间隔太长，Server端有消息到来有可能没有被及时处理。

菠萝科技注：假如处理完消息后，现在空闲，设定多久去server再拉消息？主要问题就是消息处理延迟忙等。server没消息时,但是消费者因为是定时去pull，导致空pull。

CMQ (腾讯)提供了**长轮询**的优化方法，用以平衡 Pull/Push 模型各自的缺点。消费者如果尝试拉取失败，不是直接 return，而是把连接挂在那里 wait，服务端如果有新的消息到来，把连接拉起，返回最新消息。

### ==2.介绍一下消息队列MQ的应用场景（使用消息队列的好处）==

使用消息队列主要有三点好处：解耦、异步、削峰

**1）解耦**

系统中多个系统需要接受某一系统发送的消息，此时会存在严重耦合的情况。假如不使用消息队列的话则得在发送消息的系统中需要维护多个接口，并且还需要考虑系统停止接收消息的情况，这样会严重加重系统之间的耦合性，导致消息的发送比较复杂难以维护。

但使用消息队列的话发送消息的系统就可以作为消息的生产方只需要将消息发送到 MQ 中，然后其余负责接收消息的作为消息的消费方只需要从 MQ 中取数据就行。相应的新系统接收和取消接收消息都只需要和 MQ 进行交互即可，这样的话消息的发送发就无需再进行任务处理，降低了整个系统的耦合性。

**2）异步**

有时一次请求会在系统中调用其他系统共同完成，此时使用同步去完成的话会极大的增加用户的等待时间，导致用户体验非常差，并且假如其中有系统因为网络原因导致执行失败则会导致整个请求失败。

但使用消息队列的话可以创建多个 MQ 队列来分别发布执行任务，此时在有新的请求到来时只需要向对应的 MQ 队列中发送任务执行消息，则多个系统会直接同时接收到执行任务的消息然后去执行对应的任务操作。而对于请求来说，只需要在本系统中完成任务之后再将消息发送出去之后就不用在去管其余系统的执行。这样就做到了任务异步执行来做到接口的性能优化。

**3）削峰**

在没有使用 MQ 的时候系统在流量高峰期的时候直接去访问 Mysql 数据库的话则 Mysql 可能会被直接打死（一般情况下每秒2000就到极限了），然后整个系统崩溃，导致整个系统不可用。然后在其余的低峰期的时候就不会有那么多的请求。

但使用 MQ 的话就可以实现削峰，可以直接将所有的请求都直接写入到 MQ 中，然后对应所需执行的系统可以慢慢的从 MQ 中**拉取**自己能够承受的请求数量来进行处理，这样就能保证系统是不会崩溃掉的。但是会存在一些请求的短暂积压，不过在整个高峰期的话积压也不会非常严重。

### 2.那么使用消息队列会带来什么问题?考虑过这些问题吗?

**可用性降低**： 系统可用性在某种程度上降低，为什么这样说呢？在加入MQ之前，你不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后你就需要去考虑了！

**复杂性提高**： 加入MQ之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！ 

**一致性问题**： 万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!

### 3.介绍一下你知道哪几种消息队列,该如何选择呢?

ActiveMQ、RabbitMQ、RocketMQ、Kafka 等几种常见的消息队列的比较：

- **ActiveMQ** 吞吐量到万级；社区算是比较成熟；功能强大；**比较早期所使用到的消息队列，但是会有偶尔丢失消息的可能性**。但是较目前来说，ActiveMQ 的性能比较差，而且版本迭代很慢，不推荐使用。 
- **RabbitMQ** 在吞吐量方面虽然稍逊于 Kafka 和 RocketMQ 但也达到了万级；但是由于它**基于 erlang 开发，所以并发能力很强， 性能极其好，延时很低，达到微秒级；并且提供详细的后台管理界面；而且社区很活跃，适合小中型公司使用**。但是也因为 RabbitMQ 基于 erlang 开发，所以国内很少有公司有实力做 erlang源码级别的研究和定制；如果业务场景对并发量要求不是太高（十万级、百万级），那这四种消息队列 中，RabbitMQ 一定是你的首选。
- **RocketMQ** 阿里出品，Java 系开源项目；吞吐量10万，可以做到大规模吞吐；性能很好，**支持分布式结构；可以支撑大规模的topic数量，支持复杂的 MQ 业务场景**；但是社区活跃度相对较为一般，不过也还可以。 并且由于是阿里公司维护，有被抛弃的风险，**适合有一定技术实力的大中型公司采用，可以自己对源码进行定制**。
- **kafka** 提供超高的吞吐量，单机100万，ms 级的延迟，**极高的可用性以及可靠性，而且分布式可以任意扩展**。同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。**在大数据领域中实时计算以及日志采集中经常采用，已经成为业内标准**。 kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，这点轻微影响可以忽略。

我主要使用过 RabbitMQ，是由 erlang 语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列。并且 Spring Boot 中也集成了 RabbitMQ。

补充知识：

**JMS**（JAVA Message Service,java消息服务）是java的消息服务，JMS的客户端之间可以通过JMS服务进行异步的。

消息传输。JMS（JAVA Message Service,Java消息服务）API是一个消息服务的标准或者说是规范，允许应用程序组件基于JavaEE平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。

**ActiveMQ 就是基于 JMS 规范实现的**。

**AMQP**（Advanced Message Queuing Protocol）一个提供统一消息服务的应用层**高级消息队列协议**（二 进制应用层协议），是**应用层**协议的一个**开放标准**,为面向消息的中间件设计，兼容 JMS。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。

总结：

- AMQP 为消息定义了线路层（wire-level protocol）的协议，而JMS所定义的是API规范。在 Java 体系中，多个 client均可以通过JMS进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而AMQP天然具有跨平 台、跨语言特性。 
- JMS 支持TextMessage、MapMessage 等复杂的消息类型；而 AMQP 仅支持 byte[] 消息类型（复杂的类型可序列化后发送）。 
- 由于Exchange 提供的路由算法，AMQP可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列和主题/订阅 方式两种。

**RabbitMQ 就是基于 AMQP 协议实现的**。

### 4.如何保证消息队列的高可用？

因为在系统中引入了 MQ 之后会导致系统的可用性降低（引入MQ所带来的缺点之一），所以就必须去解决这个问题。

因为我只使用过 rabbitMQ，因此主要回答该 MQ 的高可用是如何保证的。

RabbitMQ主要是基于**主从结构**来进行高可用性设计（但并不是分布式的），主要有三种模式：

1）**单机模式**：测试使用；

2）**普通集群模式**：在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。但是创建的 queue 只会放在一个实例上去运行（元数据和实际数据），但是其他每个实例都同步 queue 的**元数据**。当有消费者消费数据的时候则会从具有实际数据的节点上拉取实际的数据。这种模式只是实现了将多个消费者来连接到其他实例节点上来获取数据，但是实际的数据还是只在一台机器上。缺点：会在rabiitmq集群内部产生大量的数据传输；可用性几乎没什么保障，假如保存实际数据的节点宕机了整个集群也就不可用了。

3）**镜像集群模式**：这才是 RabbitMQ 支持高可用的模式，和普通集群模式不同的是，创建的 queue 无论元数据还是 queue 中保存的真实数据都会存在于多个实例上。然后每次生产者产生消息的时候都会自动的将消息在多个 queue 中间进行**同步**（每个节点上都有queue的完整镜像）。这样的好处在于其中一台节点宕机了，其他的还可以继续使用。但是缺点是不是分布式的，体现在性能开销增加（需要同步所有的queue）并且损失了集群的扩展性（增加的节点也要同步所有的数据）。开启方式需要在管理控制台中新增景象集群模式的策略，当再次创建queue的时候就可以应用这个策略。

### 5.如何保证消息不被重复消费呢？（如何保证消息消费时的幂等性？）

RabbitMQ 不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。

RabbitMQ、RocketMQ、Kafka，都有可能会出现消息重复消费的问题。因为这问题通常不是 MQ 自己保证的，是**由开发者来保证**的。

RabbitMQ为了保证消息必达，**消息上下半场均可能发送重复消息**，如何保证消息的幂等性呢？

幂等性就是指一个数据不论重复来多次都得保证对应的数据是不会改变的，不能出错。也就是一条数据重复出现多次只会处理一次。

**上半场**

MQ-client生成**inner-msg-id**，保证上半场幂等。

这个ID全局唯一，业务无关，由MQ保证。 

**下半场**

业务发送方带入**biz-id**，业务接收方去重保证幂等。

这个ID对单业务唯一，业务相关，对MQ透明。

结论：**幂等性，不仅对MQ有要求，对业务上下游也有要求。**

在鑫课堂项目中订单系统出可能会出现幂等性的问题，采用办法就是将发送的消息都保存在 Mysql 数据库中，然后每次使用定时任务从数据库中读取任务记录将其发送到 MQ 中去，为了保证不重复发送消息使用到了**乐观锁**来读取任务，具体是使用**版本号机制**来实现乐观锁，每发送了一条消息之后就将版本号加一，下一次扫描就不会处理该任务了，此过程使用本地事务控制。消息的消费方在处理完选课任务之后也会将数据写入到数据库中，保证了消息的幂等性。

### ==6.如何保证消息的可靠性传输？（如何处理消息丢失的问题？）==

RabbitMQ 重点传输核心业务，数据是不能弄丢的。在鑫课堂项目中的订单系统中也使用到了消息的可靠性机制。

RabbitMQ **在生产者发送消息到 RabbitMQ、RabbitMQ本身保存消息、RabbitMQ发送消息到消费者**这三个过程中都有可能因为网络原因或者机器宕机等问题而导致消息丢失。

1）**生产者弄丢消息**：将 Channel 设置为 **confirm 机制**，然后直接发送消息就不用管了，confirm机制会**异步**控制消息的可靠性。RabbitMQ 在接收到消息之后就会回调本地的一个接口通知该消息已经成功接收；假如在接收消息的时候报错了也会回调对应的接口告诉该消息发送失败。该方法也会保证消息的吞吐量不受影响。还有一种方法是事务模式。但是一般情况下会选择非阻塞异步的 Confirm 机制来实现，在鑫课堂项目中也是使用到这种方式的。

2）**RabbitMQ 弄丢数据**：为了防止 RabbitMQ 弄丢数据必须得将其设置为**持久化**的，这样消息写入之后会持久化到**磁盘**中去。持久化需要两个步骤：**第一步是创建 queue 的时候需要将其设置为持久化的**，这样只会持久化保持 queue 的元数据；**第二步是发送消息的时候将消息的 deliveryMode 设置为 2**，这样会将消息本身进行持久化。这样 RabbitMQ 就算挂了也会从磁盘上恢复数据。但是防止假如 RabbitMQ 开启了持久化但是有消息发送到 RabbitMQ，但是还没来得及持久化就挂了，这时在内存中的数据也是会丢失的，虽然数据量很小。这时就可以将 Confirm 机制和持久化机制结合使用，只有当持久化成功之后才通知生产者 ack 就可以避免这个问题了。

所谓持久化，就是RabbitMQ会将内存中的数据(**Exchange 交换器，Queue 队列，Message 消息**)固化到**磁盘**，以防异常情况发生时，数据丢失。理论上可以将所有的消息都设置为持久化，但是这样会严重影响RabbitMQ的性能。因为写入磁盘的速度比写入内存的速度慢得不止一点点。对于可靠性不是那么高的消息可以不采用持久化处理以提高整体的吞吐量。**在选择是否要将消息持久化时，需要在可靠性和吞吐量之间做一个权衡。**

3）**消费者弄丢消息**：消费者弄丢数据的原因在于开启了 **autoAck**机制，导致其在消费消息的过程中就自动通知 RabbitMQ 消息消费完成，但是此时又恰好出现了系统宕机导致这条消息其实并没有成功消费。解决方案就是只需要将 autoAck 机制关闭，然后当消息处理完成之后自己发送一个对应的 ack 到 RabbitMQ 中。

### 7.如何保证消息的顺序性？

RabbitMQ消息会出现乱序的情况：一个 queue 多个 consumer 会导致消息乱序（写入queue的数据只会被一个消费者进行消费，也就是RabbitMQ的工作队列模式，即 RabbitMQ 发送到分布式系统的场景）。

解决方案：将业务拆分为多个 queue，每个 queue 对应一个 consumer，可以在 consumer 内部维护一个 queue 来排队任务然后底层使用 worker 来处理。

### ==8.如何解决消息队列的延时以及过期失效问题？（消息队列满了之后应该怎么处理？有几百万消息积压几小时，如何解决？）==

这几个问题其实都是一个问题，都是**消费者端出现了问题导致消息没有被及时消费所导致的**。此时可以分为如下两种情况来处理：

**1）大量消息积压在 MQ 中几个小时了还没解决：**

一般这种情况下只能操作临时紧急扩容了，具体的操作步骤如下：

1、首先修复 consumer 的问题，保证其的消费速度，然后将现有的速度较慢的 consumer 停掉

2、新建一个 exchange，然后临时建立好原先10倍或者20倍的queue的数量

3、然后写一个临时分发数据的 consumer 程序，这个程序部署上去来消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue，不要落库。

4、然后使用新建的 consumer 来将消息快速的消费掉。这种做法相当于是临时将 queue 和 concumer 资源扩大10倍，以正常情况下的10倍速度来消费数据。

5、等快速消费完积压的数据之后，得恢复原先的部署架构，重新用原先的 consumer 机器来消费消息。

**2）消息过期已经被删掉了：**

对于 RabbitMQ 来说，RabbitMQ 可以设置过期时间 TTL，如果积压的消息时间超过了这个时间之后就会被 RabbitMQ 给清理掉。这样也只能等用户休息时间写程序将丢失的那部分数据找回来然后重新写入 RabbitMQ 中。

### 9.如果让你写一个消息队列，你会如何进行架构设计？

可以按照现有的一些比较优秀的消息队列的设计方式来进行介绍，也是主要通过消息队列中比较重要的几个点来介绍：

1、首先消息队列得支持可伸缩，也就是支持分布式。这里可以参考 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，保存一部分数据。

2、其次为了保证消息的可靠性，得让消息队列支持本地化操作。让数据顺序写入到磁盘中，因此磁盘顺序读写的性能高。然后保证在消费者、MQ、生产者之间的消息不回丢失。

3、最后还得保证消息的可用性，得让消息队列支持高可用保障。执行多副本leader 以及 foller 的机制，让 broker 挂了之后还可以重新选举 leader 来对外进行服务。