# 分布式缓存

### 1.在项目中分布式缓存是如何使用？缓存使用不当会造成什么后果？

#### （1）项目中缓存是如何使用的？

鑫课堂项目中的单点登录业务实现中使用到了分布式缓存来保存用户的身份信息。我们构建了一个认证系统，然后在该系统中使用 Redis 存储用户的身份信息。认证服务基于 Spring Security Oauth2 进行构建，并在其基础上作了一些扩展，采用JWT令牌机制，并自定义了用户身份信息的内容。将用户的 token 和 jwt 令牌存储在 redis 中。token作为 key，jwt 令牌作为 value。用户登录过程中将对应的身份信息保存到缓存中，在用户访问其他子系统的时候从缓存中读取用户的身份信息对用户进行身份验证和授权。

#### （2）使用缓存的好处？

主要从“高性能”和“高并发”这两点来看待这个问题。核心实现都是 redis 将数据保存在内存中保证的。

**1）高性能**

假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。然后可以将从数据库访问的数据放到到缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。因为操作缓存就是直接操作内存，所以速度相当快，这样就可以提高系统访问数据的性能。当数据发生改变的时候只需要同时改变缓存中相应的数据即可！

**2）高并发**

直接操作数据库是承受不了高并发的，像 Mysql 数据库建议的并发数是 2000/s，这是由于 Mysql 是比较重的数据库，而且数据都是保存在硬盘中的，每次从硬盘中读取是非常耗费时间的。但是缓存不一样，缓存是保存在内存中的，内存是可以支撑每秒十几万的并发数量的。这样就可以提高系统的并发数量。

#### （3）常见缓存的缺点？

1、数据双写不一致

2、缓存雪崩

3、缓存穿透

4、缓存并发竞争

以上的这些缺点的详细介绍以及具体的解决方案后续介绍。

### 2.redis 和 memcached 有什么区别？redis 的线程模型是什么？为什么单线程的redis比多线程的 memcached 效率要高得多（为什么redis 是单线程的但是还是可以支撑高并发？）

redis 其实是单线程异步工作模型。

#### （1）redis 和 memcached 的区别？

**1）redis支持服务器端的数据操作**：redis相比较于memcached来说，拥有更多的数据结构和支持更丰富的数据操作。

**2）集群模式**：memcached 没有原生的集群模式，但是 redis 是原生支持 cluster 模式的。

#### （2）redis 的单线程模型

**1）文件事件处理器**

redis 是基于 reactor 模式开发了网络事件处理器，这个处理器就叫做文件事件处理器（file event handler）。这个**文件事件处理器是单线程的，所以redis才叫单线程模型**。它采用 **IO 多路复用机制**同时监听多个 socket，将产生事件的 socket 压入内存队列中，然后事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。

**2）客户端和redis通信的一次流程**

![](./images/60.png)

要明白，通信是通过 socket 来完成的。

首先，Redis 服务端进程初始化的时候，会将 server socket 的 `AE_READABLE` 事件与连接应答处理器关联。

客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给**连接应答处理器**。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。

假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 socket01 会产生 `AE_READABLE` 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 `AE_READABLE` 事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与命令回复处理器关联。

如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok` ，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。

这样便完成了一次通信。

#### （3）问什么 redis 单线程模型也能效率这么高？

- redis 单线程模型的核心是基于**非阻塞的IO多路复用**，IO多路复用会同时**轮询**的监听多个 socket，然后直接将对应的socket事件压入到队列中去。然后就继续监听其他的socket，整个流程是非阻塞的。
- 整体的流程都是**纯内存操作**的，性能非常高。
- 单线程也可以避免多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。

### 3.redis都有哪些数据类型，分别在哪些场景下使用比较合适？

五种数据类型：Strings, Hashes, Lists, Sets, Sorted Sets，鑫课堂项目中使用到了string数据结构，用来存放用户token对应的jwt对象。

#### 字典

**1）字典在redis中的应用**

字典在 Redis 中的应用广泛， 使用频率可以说和 SDS 以及双端链表不相上下， 基本上各个功能模块都有用到字典的地方。

其中， 字典的主要用途有以下两个：

1. **实现数据库键空间（key space）；**
2. **用作 Hash 类型键的底层实现之一；**

**2）字典实现**

Redis 选择高效、实现简单的**哈希表**，作为字典的底层实现。redis的字典采用**拉链法**来解决冲突。

为了在字典的键值对不断增多的情况下保持良好的性能， 字典需要对所使用的哈希表（`ht[0]`）进行 **rehash** 操作： 在不修改任何键值对的情况下，对哈希表进行**扩容**， 尽量将比率维持在 1:1 左右。

rehash 程序并不是在激活之后，就马上执行直到完成的， 而是**分多次、渐进式**地完成的。

**3）rehash**

字典的 rehash 操作实际上就是执行以下任务：

1. 创建一个比 `ht[0]->table` 更大的 `ht[1]->table` ；
2. 将 `ht[0]->table` 中的所有键值对迁移到 `ht[1]->table` ；
3. 将原有 `ht[0]` 的数据清空，并将 `ht[1]` 替换为新的 `ht[0]` ；

经过以上步骤之后， 程序就在不改变原有键值对数据的基础上， 增大了哈希表的大小。

假设这样一个场景：在一个有很多键值对的字典里， 某个用户在添加新键值对时触发了 rehash 过程， 如果这个 rehash 过程必须将所有键值对迁移完毕之后才将结果返回给用户， 这样的处理方式将是非常不友好的。

另一方面， 要求服务器必须**阻塞**直到 rehash 完成， 这对于 Redis 服务器本身也是不能接受的。

为了解决这个问题， Redis 使用了**渐进式（incremental）的 rehash **方式： 通过将 rehash 分散到多个步骤中进行， 从而避免了集中式的计算。

在哈希表进行 rehash 时， 字典还会采取一些特别的措施， 确保 rehash 顺利、正确地进行：

- 因为在 rehash 时，字典会**同时使用两个哈希表**，所以在这期间的所有**查找、删除**等操作，除了在 `ht[0]` 上进行，还需要在 `ht[1]` 上进行。
- 在执行**添加操作时，新的节点会直接添加到 `ht[1]` 而不是 `ht[0]` **，这样保证 `ht[0]` 的节点数量在整个 rehash 过程中都只减不增。

**4）总结**

- 字典是由键值对构成的抽象数据结构。
- Redis 中的数据库键和哈希键都基于字典来实现（hash键还可以使用压缩列表）。
- Redis 字典的底层实现为哈希表，每个字典使用两个哈希表，一般情况下只使用 0 号哈希表，只有在 rehash 进行时，才会同时使用 0 号和 1 号哈希表。
- 哈希表使用链地址法来解决键冲突的问题。
- Rehash 可以用于扩展或收缩哈希表。
- 对哈希表的 rehash 是分多次、渐进式地进行的（是同步的，但渐进式的可以避免同步带来的问题）。

#### Strings

**1）简单介绍**

这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。

```
set college szu
```



#### Hashes

**1）简单介绍**

这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是**这个对象没嵌套其他的对象**）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 hash 里的**某个字段**。

```
hset person name bingo
hset person age 20
hset person id 1
hget person name
person = {
    "name": "bingo",
    "age": 20,
    "id": 1
}
```

**2）实现原理**

Redis 的 Hash 类型键使用以下两种数据结构作为底层实现:

- 字典
- 压缩列表

因为压缩列表比字典更节省内存， 所以程序在创建新 Hash 键时， **默认使用压缩列表作为底层实现**， 当有需要时， 程序才会将底层实现从压缩列表转换到字典。

#### Lists

Lists 是有序列表，这个可以玩儿出很多花样。

比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。

比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

```
# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。
lrange mylist 0 -1
```

比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。

```
lpush mylist 1
lpush mylist 2
lpush mylist 3 4 5

# 1
rpop mylist
```

#### Sets

Sets 是无序集合，自动去重。

直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 Redis 进行全局的 set 去重。

可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。

把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。

```
#-------操作一个set-------
# 添加元素
sadd mySet 1

# 查看全部元素
smembers mySet

# 判断是否包含某个值
sismember mySet 3

# 删除某个/些元素
srem mySet 1
srem mySet 2 4

# 查看元素个数
scard mySet

# 随机删除一个元素
spop mySet

#-------操作多个set-------
# 将一个set的元素移动到另外一个set
smove yourSet mySet 2

# 求两set的交集
sinter yourSet mySet

# 求两set的并集
sunion yourSet mySet

# 求在yourSet中而不在mySet中的元素
sdiff yourSet mySet
```

#### Sorted Sets（Redis zset）

**1）简单实用**

Sorted Sets 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

```
zadd board 85 zhangsan
zadd board 72 lisi
zadd board 96 wangwu
zadd board 63 zhaoliu

# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）
zrevrange board 0 3

# 获取某用户的排名
zrank board zhaoliu
```

**2）底层实现**

有序集合对象的编码可以是**`ziplist`（压缩列表）或者`skiplist`**（跳表）。同时满足以下条件时使用ziplist编码：

- 元素数量小于128个
- 所有member的长度都小于64字节

以上两个条件的上限值可通过zset-max-ziplist-entries和zset-max-ziplist-value来修改。

`ziplist`编码的有序集合使用紧挨在一起的压缩**列表**节点来保存，第一个节点保存member，第二个保存score。ziplist内的集合元素按score从小到大排序，score较小的排在表头位置。

`skiplist`编码的有序集合底层是一个命名为`zset`的结构体，而一个zset结构同时包含一个**字典（哈希表）**和一个**跳表**。**跳表按score从小到大保存所有集合元素**。而**字典则保存着从member到score的映射**，这样就可以用O(1)的复杂度来查找member对应的score值。虽然同时使用两种结构，但它们会通过指针来共享相同元素的member和score，因此不会浪费额外的内存。

**3）跳表**

**跳表(skip List)**是一种随机化的数据结构，**基于并联的链表**，实现简单，插入、删除、查找的复杂度均为O(logN)。

简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供O(logN)的时间复杂度。

跳表是从简单的单链表构建而来的。在基础的链表上每相邻两个节点增加一个指针，让指针指向下下个节点。这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半。利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图：



![61](./images/61.png)

`skiplist`正是受这种多层链表的想法的启发，在基础的单链表的基础上添加上层节点。即将当前层节点每两个节点之间的节点向上扩展一层，使其成为上一层的节点，也就是**上下相邻两层链表上节点个数按照严格的2:1的对应关系**。这样上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。

但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。

skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是**为每个节点随机出一个层数(level)**。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程：

![62](./images/62.png)

从上面skiplist的**创建和插入**过程可以看出，每一个节点的层数（level）是**随机**出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。

执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。这并不是一个普通的服从均匀分布的随机数，它的计算过程如下：

- 首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。
- 如果一个节点有第i层(i>=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。
- 节点最大的层数不允许超过一个最大值，记为MaxLevel。

这个计算随机层数的伪码如下所示：

```python
randomLevel()
    level := 1
    // random()返回一个[0...1)的随机数
    while random() < p and level < MaxLevel do
        level := level + 1
    return level
```

randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为：

```python
p = 1/4
MaxLevel = 32
```

总结起来，Redis中的skiplist跟前面介绍的经典的skiplist相比，有如下不同：

- 分数(score)允许重复，即skiplist的key允许重复。这在最开始介绍的经典skiplist中是不允许的。
- 在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。
- 第1层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。
- 在skiplist中可以很方便地计算出每个元素的排名(rank)。

**4）Redis为什么用skiplist而不用平衡树？**

这里从**内存占用、对范围查找的支持和实现难易程度**这三方面总结的原因。

skiplist与平衡树、哈希表的比较

- skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
- 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
- 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。
- 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
- 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
- 从算法实现难度上来比较，skiplist比平衡树要简单得多。

### 4.redis的过期策略是怎样的？内存淘汰机制有哪些？能手写LRU吗？

缓存是基于内存的，而且内存是有限的，因此缓存中的数据是会过期的。

那么就可以在在存储数据的时候设置过期时间，在指定时间之后就会失效。但是这些事根据redis的过期策略来决定的。

#### redis的过期策略是怎么样的？

redis针对过期数据的删除策略是：**定期删除+惰性删除**

**定期删除**是指 redis 默认是每隔 **100ms** 就**随机抽取**一些设置了过期时间的 key，检查其是否过期，如果过期就删除。（注意这里是**随机抽取**的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔 100ms 就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！）

上面的定期删除机制可能会导致还有一些已经过期的数据在内存中并没有被删除，依旧占用着内存。此时就有另一个过期策略：**惰性删除**。惰性删除是指假如该数据已经过期了，那么在下一次在查找该数据的时候会直接先把该数据删除，然后不会返回任何数据。

但是上面的惰性删除是指需要在查询数据的时候才会对过期的数据进行删除。假如没有查询的话则过期的数据还是会继续留在内存中占用着内存。

那么就得需要介绍一下 redis 的内存淘汰机制：

#### redis的内存淘汰机制

redis 支持如下几种内存淘汰机制：

- noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错（这个一般没人用吧，实在是太恶心了。）
- **allkeys-lru**：当内存不足以容纳新写入数据时，在**键空间**中，移除最近最少使用的 key（这个是**最常用**的）。
- allkeys-random：当内存不足以容纳新写入数据时，在**键空间**中，随机移除某个 key（这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。）
- volatile-lru：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的 key（这个一般不太合适）。
- volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，**随机移除**某个 key。
- volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，有**更早过期时间**的 key 优先移除。

#### 手写LRU

LRU底层实现需要用到**双向链表**：

```java
class LRUCache {
    // 自定义双向链表节点
    class DLinkedNode{
        int key;
        int value;
        DLinkedNode prev;
        DLinkedNode next;
        DLinkedNode(){}
        DLinkedNode(int key, int value){
            this.key = key;
            this.value = value;
        }
    }

    // 当前使用的数据量
    private int size = 0;
    // 整体的容量
    private int capacity = 0;
    // 保存键值对数据
    private Map<Integer,DLinkedNode> map = new HashMap<>();
    // 双向链表保存当前的访问顺序
    private DLinkedNode head,tail;

    // 初始化LRU对象
    public LRUCache(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        // 使用伪头节点和伪尾节点
        head = new DLinkedNode();
        tail = new DLinkedNode();
        head.next = tail;
        tail.prev = head;
    }
    
    // get操作
    public int get(int key) {
        // 从map中进行查找对应的节点
        DLinkedNode node = map.get(key);
        if(node == null){
            return -1;
        }
        // 如果key存在则移动到头部
        move2Head(node);
        return node.value;
    }
    
    // put操作
    public void put(int key, int value) {
        // 首先查询该数据是更新还是插入
        DLinkedNode node = map.get(key);
        if(node == null){
            // 插入节点
            node = new DLinkedNode(key,value);
            map.put(key,node);
            // 将该节点添加到头部
            add2Head(node);
            this.size++;
            // 判断当前的容量是否超过总的容量
            if(this.size > this.capacity){
                // 如果超出容量删除双向链表的尾节点
                DLinkedNode tail = removeTail();
                map.remove(tail.key);
                this.size--;
            }
        }else{
            // 更新节点
            node.value = value;
            // 将节点移动到头部
            move2Head(node);
        }
    }
    // 将传入的节点移动到链表头部
    private void move2Head(DLinkedNode node){
        // 将该节点删除
        removeNode(node);
        // 将该节点添加到头节点位置上
        add2Head(node);
    }
    // 删除当前链表的尾节点
    private DLinkedNode removeTail(){
        // 获取当前链表的尾节点
        DLinkedNode node = this.tail.prev;
        // 删除该节点
        removeNode(node);
        // 将该节点进行返回
        return node;
    }
    // 删除双向链表的节点
    private void removeNode(DLinkedNode node){
        // 更改前一个节点的next指针
        node.prev.next = node.next;
        // 更改后一个节点的prev指针
        node.next.prev = node.prev;
    }
    // 将节点插入到链表的头节点
    private void add2Head(DLinkedNode node){
        node.next = this.head.next;
        this.head.next.prev = node;
        this.head.next = node;
        node.prev = this.head;
    }
}

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache obj = new LRUCache(capacity);
 * int param_1 = obj.get(key);
 * obj.put(key,value);
 */
```

### 5.怎么保证redis是高并发和高可用？redis的主从复制原理能介绍一下吗？redis的哨兵原理能介绍一下吗？

#### redis如何保证高并发以及高可用的？

**1）高并发**

redis实现高并发的瓶颈在于：机器数量，单机redis能够承载的QPS大概在上万到几万不等。

如果 redis 要支撑超过10万+的话就是使用**读写分离**操作，一般用redis都是用来支撑读的高并发，而写的请求较少。

读写分离也就是**主从架构**，一主多从，主写从读。将写请求写入到 master redis 节点上，然后 mater 将数据在同步到 slave redis 上。所有的读操作都由 slave redis 来负责。

而且这种架构的好处在于可以支持水平扩容，也就是可以通过增加 slave redis 节点来增加并发。

**主从架构 -> 读写分离 -> 高并发**

**2）高可用**

**主从架构+哨兵 -> 主备切换**

但是假如 master node 宕机之后就无法写数据了，整个系统也就不可用了，此时所有的请求都直接都直接落入到 mysql 数据库中，造成缓存雪崩。

此时就得使用 redis 的高可用架构，也就是**故障转移，failover**，也可以叫做主备切换。当在 master node 故障的时候自动检测，将某个 salve node 自动切换为 master node的过程就叫做主备切换。这个过程就实现了 redis 主从架构下的高可用性。

为了监控 master node 的存活情况，就得使用到一个节点就是 sentinal node，也就是**哨兵节点**。该节点就负责监控 master node 的状态，当 master node 宕机的时候就自动选举一个 slave node 为 master node。

#### redis的主从复制原理能介绍一下吗？

**1）主从架构**

redis replication 也就是 redis 的主从结构，也就是一个 master node 配置多个 slave node ，客户端将数据写入到 master node 上，然后返回客户端数据写入成功的提示。之后 master node 再将数据复制到 slave node 上就可以了，采用的是异步执行的方式。

当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。

如果这是 slave node 首次连接 master node 的话，那么会触发一次 **full resynchronization**，开始 full resynchronization 的时候，master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给 salve，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master node 内存中缓存的这些数据也会通过写命令发送到 salve，slave会同步这些数据。

如果这是 salve node 重新连接到 master node，那么 master node 仅仅会复制给 salve node 缺少的数据。

slave node 和master node 如果发生了网络故障，断开了连接则会自动重连。master node 发现有多个 salve node 都来重新连接，仅仅会启动一个 RDB save 操作，用一份数据服务所有的 slave node。

**2）主从架构中两种会丢失数据的情况**

1、**异步主从复制**：因为 master -> slave 的复制是异步的，所以可能有部分数据还没有复制到 salve，master 就宕机了，此时这部分数据就丢失了。

2、**脑裂问题**：redis集群出现了异常性的有相同数据、相同工作的两个 master 节点称之为 redis 的脑裂问题。也就是 master 节点由于网络问题无法和其他的 salve node 和 sentinal node 进行通信， sentinal node 就以为 master 节点宕机了，然后就执行故障转移将一个 salve node 选举为 master node，但其实原先的 master node 好在正常工作，这样就导致出现了两个 master node。

此时假如有 client 还是继续向原先旧的 master node 写入数据，当脑裂问题解决的时候 sentinal node 会将原先的 master node 作为新的 salve node，然后同步此时的 master node 数据，这样就会导致原先在旧的 master node 上的一部分数据就丢失了。

**3）redis数据丢失的解决方案？**

解决数据丢失就靠两个参数的设置：

```json
min-slave-to-write 1
min-slave-max-lag 10 
```

以上配置的内容是：要求至少有1个salve 数据复制和同步的延迟不能超过10s。也就是说如果说一旦所有的 salve，数据复制和同步的延迟都超过了10s，那么这个时候 master 就不会在接收任何请求了。

**1）异步主从复制丢失解决**

有了 min-slave-max-lag 这个配置，就可以确保说，一旦slave复制数据和ack延时太久，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低到可控的范围内。

**2）脑裂数据丢失的解决**

如果一个 master 出现了脑裂，跟其他的 salve 丢失了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 salve 发送数据，而且 salve 超过 10s没有给自己 ack消息，那么就直接拒绝客户端的写请求。

这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失。然后将旧 client 上的数据进行数据降低操作，先写入到磁盘中，然后在重新写入到新 master 上。

#### redis 的哨兵原理能介绍一下吗？

**1）哨兵的介绍**

sentinal，中文名就是哨兵

哨兵是redis集群架构中非常重要的一个组件，主要的功能如下：

- **集群监控**：负责监控 redis master 和 salve 进程是否正常工作；
- 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员；
- **故障转移**，如果 master node 挂掉了，会自动转移到 salve node 上；
- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址；

哨兵本身是分布式的，需要作为一个哨兵集群去运行，相互协同工作。

并且在故障转移的过程中，如果一个 master node 宕机了，此时需要大部分的哨兵都同意才可以选举一个 slave node 为 master node，这里涉及到了分布式选举的问题。

**2）哨兵的核心知识**

- 哨兵至少需要**3**个实例来保证自己的健壮性；
- 哨兵+redis主从架构是不会保证数据零丢失的，只能保证 redis 集群的高可用性；

**3）为什么redis哨兵集群只有2个节点无法正常工作？**

如果哨兵集群设置了2个节点，同时设置 quorum =1，也就是说当 master 宕机的时候两个哨兵中只要有一个哨兵认为可以进行故障转移就会选出一个哨兵来完成故障转移操作。

但是得有个前提就是 majority，也就是哨兵运行的最小个数。（2个哨兵的majority是2，3个哨兵的majority是2，5个哨兵的majority是3），也就是说只有当2个哨兵都运行的时候才可以执行故障转移。假如一个哨兵宕机的话就会出现无法执行故障转移的问题。

这就是为什么不能设置2个节点的哨兵集群。

而经典的哨兵集群是三个节点的，这样就算有一个哨兵节点宕机了也是可以继续执行故障转移的。

**4）sdown和odown转换机制**

sdown 和 odown 是两种宕机状态

sdown是主观宕机，就是一个哨兵如果觉得一个 master 宕机了，那么就是主观宕机。

odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机。

sdown的达成条件很简单，如果一个哨兵ping一个master，超过了 is-master-down-after-milliseconds 指定的毫秒数之后就主观认为master宕机了。

sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个 master 是 sdown了，那么就认为是 odown le，客观认为 master 宕机。

**5）哨兵的自动发现机制**

哨兵互相之间的发现，是通过 Redis 的 `pub/sub` 系统实现的，每个哨兵都会往 `__sentinel__:hello` 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。

每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 `__sentinel__:hello` channel 里**发送一个消息**，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。

每个哨兵也会去**监听**自己监控的每个 master+slaves 对应的 `__sentinel__:hello` channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。

每个哨兵还会跟其他哨兵交换对 `master` 的监控配置，互相进行监控配置的同步。

**6）slave 配置的自动纠正**

哨兵会负责自动纠正 slave 的一些配置，比如 slave 如果要成为潜在的 master 候选人，哨兵会确保 slave 复制现有 master 的数据；如果 slave 连接到了一个错误的 master 上，比如故障转移之后，那么哨兵会确保它们连接到正确的 master 上。

**7）slave->master 选举算法**

如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：

- 跟 master 断开连接的时长
- slave 优先级
- 复制 offset
- run id

如果一个 slave 跟 master 断开连接的时间已经超过了 `down-after-milliseconds` 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。

```
(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state
```

接下来会对 slave 进行排序：

- 按照 slave 优先级进行排序，slave priority 越低，优先级就越高。
- 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。
- 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。

**8）quorum 和 majority**

每次一个哨兵要做主备切换，首先需要 quorum 数量的哨兵认为 odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到 majority 哨兵的授权，才能正式执行切换。

如果 quorum < majority，比如 5 个哨兵，majority 就是 3，quorum 设置为 2，那么就 3 个哨兵授权就可以执行切换。

但是如果 quorum >= majority，那么必须 quorum 数量的哨兵都授权，比如 5 个哨兵，quorum 是 5，那么必须 5 个哨兵都同意授权，才能执行切换。

**9）configuration epoch**

哨兵会对一套 Redis master+slaves 进行监控，有相应的监控的配置。

执行切换的那个哨兵，会从要切换到的新 master（salve->master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 version 号都必须是唯一的。

如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 version 号。

**10）configuration 传播**

哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 `pub/sub` 消息机制。

这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的 version 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。

### 6.redis的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体的底层是如何实现的？

这几个问题都是考虑仅仅将数据缓存在内存中，但是此时redis宕机了，在重启，内存里的数据就全部丢失了。

因此就得使用 redis 的持久化机制来将数据写入内存的同时慢慢的将数据写入到磁盘文件中，进行持久化。这样 redis 宕机重启之后就会自动的从磁盘上加载之前持久化的数据，这样仅仅只会丢失少量的数据，但至少不是全部数据丢失。

假如没有做持久化的话，那么当redis出现灾难性故障之后重启redis之后，因为redis 中没有数据则会导致 redis 出现**缓存雪崩**，即所有的请求都没有经过缓存而是直接落到了 mysql 等数据源。这样会导致 mysql 挂掉，导致整个系统崩溃。

#### redis的持久化机制

redis持久化的意义在于**故障恢复**，当redis集群出现灾难级的问题的时候会导致在内存中的数据会丢失。为了应对故障发生之后的数据恢复，必须得对redis的重要数据进行持久化，也就是将内存数据写入到磁盘中，然后定期的将磁盘备份定期同步和备份到一些云存储服务上，这样只会导致丢失少量的数据，不至于丢失全部的数据。

主要有两种持久化机制：RDB（内存快照）、AOF（命令追加）

**1）RDB**

RDB持久化机制会每隔一定时间生成 redis 内存中数据的完整快照。

**2）AOF**

AOF持久化机制会将 redis 中每条写入的命令作为日志，以 append-only 的模式写入到一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入命令来重新构建整个缓存数据。

当有 redis 的写入命令到来的时候会自动将其写入到 AOF 持久化文件中，注意这里其实会首先将数据写入到 os cache 中，然后操作系统每隔 1s 会执行一次 fsync 操作将 os cache 中的数据写入到文件中。

注意由于 redis 的内存是有限的，因此不可能一直的进行数据的写入，当写入的数据达到 redis 的内存总量的时候会执行 redis 的内存淘汰机制（LRU等）来清理掉一些没用的数据。但是这个操作是不影响 AOF 的持久化日志文件的，也就是 AOF 的持久化日志文件是只保存写入的命令的。这样当 redis 在内存淘汰机制之后就会继续执行数据写入命令，而 AOF 也是会继续将命令以日志的形式写入到 AOF 日志文件中去。这样就会导致 AOF 日志文件持续增大。这个时候当 redis 继续写入数据到内存满的时候 redis 就会执行 rewrite 操作，将当前内存中的数据重新写入到一个新的 AOF 日志文件中，然后删除旧的 AOF 日志文件，同时新写入的数据也会直接写入到新的 AOF 文件中。

而保存的 AOF 文件则可以将其同步备份到云服务中。

**3）总结**

RDB机制是内存快照；AOF机制是写命令追加。

当同时使用 RDB 和 AOF 的时候，在 redis 重启的时候会选择使用 AOF 来重新构建数据，因为 AOF 中的数据更加完整。

#### 不同持久化机制的优缺点

**1）RDB机制的优点**

- RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式非常适合做冷备份。
- RDB是直接写到redis内存中去的，在一定的时候才会fork出一个子进程将其写入到磁盘，这样会保证RDB的性能非常高。
- RDB在恢复的时候直接将其加载到内存中即可，相比较于AOF需要对指令进行回放操作更加快速。

综上所述，RDB非常适合做冷备份。

**2）RDB机制的缺点**

- 可能会丢失比较多的数据（这也是RDB最大的却带你，不适合作为第一恢复方案）。由于RDB是每隔一定的时间才将内存快照写入到磁盘，假如在时间间隔中redis出现故障的话会导致丢失在这个时间间隔中的数据。
- RDB每次在fork子进程执行RDB数据快照文件的时候，如果数据文件特别大，可能会导致当前redis服务暂停一段时间（一般不要让RDB的时间间隔太长，避免文件过大对redis的性能造成影响）。

**3）AOF机制的优点**

- AOF可以更好的保护数据不丢失，一般AOF会每隔1s通过后台线程执行一次fsync操作，最多丢失1s的数据。
- AOF日志文件以append-on模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损。
- AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 reweitr 的时候，后台会新创建一个线程来创建一个新的日志文件。
- AOF日志文件是可读的，方便人员对其进行修改。

**4）AOF机制的缺点**

- 相比较于RDB，AOF的日志文件更大。
- 数据恢复时间较长。
- AOF开启后会导致redis的写数据性能降低。但一般配置为每秒fsync一次日志文件，性能也还是可以的。
- AOF记录的日志有可能出现bug。

Redis **4.0** 开始支持 **RDB 和 AOF 的混合持久化**（默认关闭）。

如果把混合持久化打开，AOF 重写的时候就直接**把 RDB 的内容写到 AOF 文件开头**。

这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。

当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。









