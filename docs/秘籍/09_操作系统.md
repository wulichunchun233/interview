# 操作系统

## 操作系统基础

### 1.系统调用（用户态如何切换到内核态？）

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

1. **用户态(user mode) **： 用户态运行的进程或可以直接读取用户程序的数据。
2. **系统态(kernel mode)**：可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类（用户态如何切换到内核态的方法）：

- 设备管理。完成设备的请求或释放，以及设备启动等功能。
- 文件管理。完成文件的读、写、创建及删除等功能。
- 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
- 进程通信。完成进程之间的消息传递或信号传递等功能。
- 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

### 2.为什么要分用户态和内核态？

简单以一句话是为了安全， 在CPU的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。

如果所有的程序都能使用这些指令，那么系统死机的概率将大大增加。

所以出于安全的考虑，CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令。

### 3.虚拟地址空间和物理地址空间的区别和联系？

所谓**地址空间**，是地址访问可以达到的所有地址的集合。

**物理地址空间**是实在的存在于计算机中的一个实体，也就是物理内存。

计算机上都存在一个程序能够产生的地址集合，我们称之为地址范围。这个范围的大小由CPU的位数决定，例如一个32位的CPU，它的地址范围是0~0xFFFFFFFF (4G),而对于一个64位的CPU，它的地址范围为0~0xFFFFFFFFFFFFFFFF (64T).这个范围就是我们的程序能够产生的地址范围，我们把这个地址范围称为**虚拟地址空间**，该空间中的某一个地址我们称之为虚拟地址。

与虚拟地址空间和虚拟地址相对应的则是**物理地址空间**和物理地址，大多数时候我们的系统所具备的物理地址空间只是虚拟地址空间的一个子集。

### 4.如何实现虚拟地址空间？

现代操作系统普遍采用虚拟内存管理（Virtual Memory Management）机制，这需要处理器中的MMU（Memory Management Unit，内存管理单元）提供支持。

从虚拟地址到物理地址的运行时映射是由内存管理单元（MMU）的硬件设备来完成。CPU 在访问内存的时候都需要通过 MMU 把虚拟地址转化为物理地址，然后通过总线访问内存。MMU 开启后 CPU 看到的所有地址都是虚拟地址，CPU 把这个虚拟地址发给 MMU 后，MMU 会通过页表在页表里查出这个虚拟地址对应的物理地址是什么，从而去访问外面的 DDR（内存条）。

MMU 是通过页表把虚拟地址转换成物理地址，页表是一种特殊的数据结构，放在系统空间的页表区存放逻辑页与物理页帧的对应关系，每一个进程都有一个自己的页表。

### 5.介绍下mmap的原理？

mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图所示：

![](https://images0.cnblogs.com/blog2015/571793/201507/200501092691998.png)

由上图可以看出，进程的虚拟地址空间，由多个虚拟内存区域构成。虚拟内存区域是进程的虚拟地址空间中的一个同质区间，即具有同样特性的连续地址范围。上图中所示的text数据段（代码段）、初始数据段、BSS数据段、堆、栈和内存映射，都是一个独立的虚拟内存区域。而为内存映射服务的地址空间处在堆栈之间的空余部分。

linux内核使用vm_area_struct结构来表示一个独立的虚拟内存区域，由于每个不同质的虚拟内存区域功能和内部机制都不同，因此一个进程使用多个vm_area_struct结构来分别表示不同类型的虚拟内存区域。各个vm_area_struct结构使用链表或者树形结构链接，方便进程快速访问，如下图所示：

![](https://images0.cnblogs.com/blog2015/571793/201507/200501434261629.png)

vm_area_struct结构中包含区域起始和终止地址以及其他相关信息，同时也包含一个vm_ops指针，其内部可引出所有针对这个区域可以使用的系统调用函数。这样，进程对某一虚拟内存区域的任何操作需要用要的信息，都可以从vm_area_struct中获得。mmap函数就是要创建一个新的vm_area_struct结构，并将其与文件的物理磁盘地址相连。

mmap内存映射的实现过程，总的来说可以分为三个阶段：

**（一）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域**

1、进程在用户空间调用库函数mmap，原型：void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);

2、在当前进程的虚拟地址空间中，寻找一段空闲的满足要求的连续的虚拟地址

3、为此虚拟区分配一个vm_area_struct结构，接着对这个结构的各个域进行了初始化

4、将新建的虚拟区结构（vm_area_struct）插入进程的虚拟地址区域链表或树中

**（二）调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系**

5、为映射分配了新的虚拟地址区域后，通过待映射的文件指针，在文件描述符表中找到对应的文件描述符，通过文件描述符，链接到内核“已打开文件集”中该文件的文件结构体（struct file），每个文件结构体维护着和这个已打开文件相关各项信息。

6、通过该文件的文件结构体，链接到file_operations模块，调用内核函数mmap，其原型为：int mmap(struct file *filp, struct vm_area_struct *vma)，不同于用户空间库函数。

7、内核mmap函数通过虚拟文件系统inode模块定位到文件磁盘物理地址。

8、通过remap_pfn_range函数建立页表，即实现了文件地址和虚拟地址区域的映射关系。此时，这片虚拟地址并没有任何数据关联到主存中。

**（三）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝**

注：前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。

9、进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常。

10、缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程。

11、调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中。

12、之后进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。

注：修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步, 这样所写的内容就能立即保存到文件里了。

### 6.虚拟内存

虚拟内存使得应用程序认为它拥有连续的可用内存，这样一来，就在逻辑层面上扩大了内存容量。但是实际上，只是把比较常用的内存片段取出来了而已，还有部分资源是放在磁盘存储器上的，需要的时候再进行页面调度。

调度方式有，分页式，段式，段页式。比较流行方式是段页式，他结合了前两者的优点，以页为单位替换，以段为单位使用。

常见的替换替换算法有4种，随机算法，先进先出算法，LRU算法，最优算法。 比较常使用的是LRU算法，他在redis里也有使用，当redis的内存满了的时候就是使用LRU算法替换掉旧内存。

### 7.读取文件的流程？

**读文件**

1、进程调用库函数向**内核**发起读文件请求；

2、**内核**通过检查进程的**文件描述符**定位到**虚拟文件系统**的已打开**文件列表表项**；

3、调用该文件可用的系统调用函数**read()**

3、**read()**函数通过**文件表项**链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的**inode**；

4、在**inode**中，通过文件内容偏移量计算出要读取的页；

5、通过**inode**找到文件对应的**address_space**；

6、在**address_space**中访问该文件的**页缓存树**，查找对应的页缓存结点：

（1）如果页缓存命中，那么直接返回文件内容；

（2）如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页；重新进行第6步查找页缓存；

7、文件内容读取成功。

**写文件**

前5步和读文件一致，在address_space中查询对应页的页缓存是否存在：

6、如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去。

7、如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页。此时缓存页命中，进行第6步。

8、一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块。有两种方式可以把脏页写回磁盘：

（1）手动调用sync()或者fsync()系统调用把脏页写回

（2）pdflush进程会定时把脏页写回到磁盘

同时注意，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放。

### ==8.内存中的堆栈==

**堆栈：一种数据结构，一个在程序运行时用于存放的地方**

在数据结构中，**栈**是一种可以实现“先进后出”（或者称为“后进先出”）的存储结构；相对于栈的“先进后出”特性，**堆**则是一种经过排序的树形数据结构，常用来实现优先队列等，堆是一种特殊的完全二叉树。其中，节点是从左到右填满的，并且最后一层的树叶都在最左边（即如果一个节点没有左儿子，那么它一定没有右儿子）；每个节点的值都小于（或者都大于）其子节点的值。

在 C 语言中，内存分配方式不外乎有如下三种形式：

1. 从静态存储区域分配：它是由编译器自动分配和释放的，即内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在，直到整个程序运行结束时才被释放，如全局变量与 static 变量。
2. 在**栈**上分配：它同样也是由编译器自动分配和释放的，即在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元将被自动释放。需要注意的是，栈内存分配运算内置于处理器的指令集中，它的运行效率一般很高，但是分配的内存容量有限。
3. 从**堆**上分配：也被称为动态内存分配，它是由程序员手动完成申请和释放的。即程序在运行的时候由程序员使用内存分配函数（如 malloc 函数）来申请任意多少的内存，使用完之后再由程序员自己负责使用内存释放函数（如 free 函数）来释放内存。也就是说，动态内存的整个生存期是由程序员自己决定的，使用非常灵活。需要注意的是，如果在堆上分配了内存空间，就必须及时释放它，否则将会导致运行的程序出现内存泄漏等错误。

栈内存是**由编译器自动分配与释放**的，它有两种分配方式：**静态分配**和**动态分配**。

- 静态分配是由**编译器**自动完成的，如**局部变量**的分配（即在一个函数中声明一个 int 类型的变量i时，编译器就会自动开辟一块内存以存放变量 i）。与此同时，其生存周期也只在函数的运行过程中，在运行后就释放，并不可以再次访问。
- 动态分配由 **alloca 函数**进行分配，但是栈的动态分配与堆是不同的，它的动态分配是由编译器进行释放，无需任何手工实现。值得注意的是，虽然用 alloca 函数可以实现栈内存的动态分配，但 alloca 函数的可移植性很差，而且在没有传统堆栈的机器上很难实现。因此，不宜使用于广泛移植的程序中。当然，完全可以使用 C99 中的变长数组来替代 alloca 函数。

而堆内存则不相同，它完全是由程序员手动申请与释放的，程序在运行的时候由程序员使用内存分配函数（如 malloc 函数）来申请任意多少的内存，使用完再由程序员自己负责使用内存释放函数（如 free 函数）释放内存。

对栈而言，一般用于存放**函数的参数与局部变量**等；**对堆而言，具体存储内容由程序员根据需要决定存储数据。**

## 进程和线程

### ==1.进程和线程的区别？==

一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的 **程序计数器**、**虚拟机栈** 和 **本地方法栈**。

线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。

线程和进程最大的不同在于基本上**各进程是独立的**，而各线程则不一定，因为同一进程中的**线程极有可能会相互影响**。

线程执行开销小，但不利于资源的管理和保护；而进程正相反。

### ==2.IO多路复用==

IO多路复用是一种**同步IO模型**，是指使用一个**线程**来检查多个文件描述符（Socket）的就绪状态，内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。

与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。

目前支持I/O多路复用的系统调用有 **select，poll，epoll**。

select/poll/epoll之间的区别：

|            | select             | poll             | epoll                                             |
| :--------- | :----------------- | :--------------- | :------------------------------------------------ |
| 数据结构   | bitmap             | 数组             | 红黑树                                            |
| 最大连接数 | 1024               | 无上限           | 无上限                                            |
| fd拷贝     | 每次调用select拷贝 | 每次调用poll拷贝 | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 工作效率   | 轮询：O(n)         | 轮询：O(n)       | 回调：O(1)                                        |

### ==3.进程间通信的方式及其应用场景？==

- **匿名管道**：父类进程使用fork创建对应的子类进程，然后双方的通信使用的就是匿名管道。匿名管道是一个大小为4kb的**缓冲区**，只可以用于**父子类进程或者兄弟进程之间进行通信**。匿名管道是**半双工**方式进行通信的，即同时只能一个进程写，另一个进程读，数据只能单方向流动。
- **有名管道**：匿名管道只可以用于父子类进程之间进行通信，而有名管道可以用于其他进程之间进行通信。有名管道是一个严格按照**先进先出**方式执行的队列结构，有名管道以**磁盘文件**的方式存储，可以实现本机任意两个进程之间进行通信。有名管道和匿名管道一样都是**半双工**的。常用于**linux 当中 shell 执行两个命令间的数据传递**。
- **信号**：信号用于让进程接收某件事情是否发生。常用于**通知进程某个事情已经发生，比如 ctrl+c 中断事件发生**。
- **信号量**：信号量是一个**计数器**，用于多个进程对同一个**共享资源访问**，可以作为多个进程的**同步机制**。主要用于**多个进程之间需要同步的场景**。
- **共享内存**：共享内存是在**内存**中开辟一块内存来供多个进程进行读写，通常还需要一些进程同步的机制来辅助。由于**数据不需要在两个进程之间进行复制**，因此是最快的进程间通信方式。常用于**多个进程之间共享数据或者进程间需要频繁进行大量数据交互的场景**。
- **消息队列**：消息队列是一个消息的**链表**结构，存放在内存中由**消息队列标识符**进行标识。消息队列中的数据也是遵循**先进先出**的原则，但也可以按照消息的**类型**进行读取。常用于**进程间异步通信**。
- **套接字**：套接字是支持 **TCP/IP** 网络通信的编程规范。常用于**进程之间需要网络通信的场景**。

### 4.信号量怎么实现对共享资源的访问

为了获得共享资源，进程需要执行下列操作：

（1）创建一个信号量：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。

（2）等待一个信号量：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。

（3）挂出一个信号量：该操作将信号量的值加1，也称为V操作。

为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。

Linux环境中，有三种类型：Posix（可移植性操作系统接口）有名信号量（使用Posix IPC名字标识）、Posix基于内存的信号量（存放在共享内存区中）、System V信号量（在内核中维护）。这三种信号量都可用于进程间或线程间的同步。

### ==5.线程间的同步的方式？==

1. **互斥量(Mutex)**：采用**互斥对象**机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较。

### 6.进程的调度算法？

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。 

### ==7.线程间如何切换？==

一个进程的多个线程间切换的时候就涉及到了**上下文切换**。

简单来说，就是有一个**时间片算法**，cpu会给每个线程一个时间片来执行，时间片结束之后就保存这个线程的状态，然后切换到下一个线程去执行。这也就是多线程并发执行的原理，就是多个线程反复切换，每个线程在一个时间片里执行。

### ==8.死锁是什么？为什么会出现死锁？如何解决？==

死锁是多**线程**并发可能会遇到的一个问题。

**1）死锁是什么？**

当线程A持有独占锁a，并尝试去获取独占锁b的同时，线程B持有独占锁b，并尝试获取独占锁a的情况下，就会发生AB两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。

**2）死锁的发生条件**

- **互斥**：一个资源每次只能被一个线程使用。
- **循环等待**：若干线程之间形成一种头尾相接的循环等待资源关系。
- **请求保持**：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
- **不可剥夺**：线程已获得的资源，在未使用完之前，不能强行剥夺。

**3）如何解决死锁？**

破坏上面四个条件之一就可以解决死锁，使用的算法是**银行家算法**。

**银行家算法**：当一个进程申请使用资源的时候，银行家算法通过先 **试探** 分配给该进程资源，然后通过**安全性算法**判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

![](https://img-blog.csdn.net/20180508204335770?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDE0Mjcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 9.线程间通信方法

- 锁机制：包括互斥锁、条件变量、读写锁
  - 互斥锁提供了以排他方式防止数据结构被并发修改的方法。
  - 读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
  - 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
- 信号机制(Signal)：类似进程间的信号处理

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

## Linux

### ==0.Linux常见命令==

```shell
# 进入文件目录
cd 文件目录

# 创建文件夹
mkdir 文件夹名

# 复制文件
cp 文件名 新文件名

# 移动以及重命名文件
mv 文件名 新文件名

# 删除文件
rm 文件名

# 查找文件
find 目录 参数

# 查找文件内容
grep 参数 正则表达式 文件名

# 修改文件
vi 文件名

# 更改文件权限
chmod a+x 文件名

# 列出当前正在运行的进程
ps aux

# 查看当前进程的运行状况
top

# 查看当前磁盘的情况
df

# 查看端口占用情况 lsof(list open files)
lsof -i:端口号
netstat -tnpl | grep 端口号
```

### ==2.Linux load averages含义？==

load average：操作系统的平均负荷，里面有三个数字，三个数字的意思分别是**1分钟、5分钟、15分钟**内系统的平均负荷，我们可以从中判断系统负荷是大还是小。

Linux load averages 是**系统负载**平均值（system load averages），它将正在运行的线程（任务）对系统的需求显示为平均运行数和等待线程数。Linux load averages 可以衡量任务对系统的需求，并且它可能大于系统当前正在处理的数量，大多数工具将其显示为三个平均值，分别为 1、5 和 15 分钟值。

一些解释：

- 如果平均值为 0.0，意味着系统处于空闲状态
- 如果 1min 平均值高于 5min 或 15min 平均值，则负载正在增加
- 如果 1min 平均值低于 5min 或 15min 平均值，则负载正在减少
- 如果它们高于系统 CPU 的数量，那么系统很可能会遇到性能问题（视情况而定）

Linux 中的 load average 已经从 “CPU load averages” 变为 “**system load averages**”。测量正在运行和等待运行的线程数（CPU，磁盘，不间断锁）。换句话说，它测量不完全空闲的线程数。优点：包含了对不同资源的需求。

在其他操作系统上，load averages 是 “**CPU load averages**”，测量 CPU 运行的数量 + CPU 可运行的线程。优点：更容易理解（仅适用于CPU）。

### ==3.系统内存占用情况==

linux下在终端环境下可以使用 **free** 命令看到系统实际使用内存的情况，一般用 **free -m** 方式查看内存占用情况（兆为单位）。

系统实际内存占用以及可用内存有如下几个加减法：

- **used=total-free** 即 **total=used+free**
- 实际内存占用：**used-buffers-cached** 即 **total-free-buffers-cached**
- 实际可用内存：**buffers+cached+free**

## 应用题

### ==1.线上服务器 CPU 100%该如何排查、定位和解决？==

**1）定位耗费CPU的进程**

`top -c`就可以显示进程列表，然后输入 `P`，按照 CPU 使用率来排序。这样就可以看到哪个进程的 CPU 负载最高。

**2）定位耗费CPU的线程**

`top -Hp 进程号`，然后输入 `P`，按照 CPU 的使用率排序。这样就可以看到这个进程里哪个线程耗费 CPU 最高。

**3）定位哪段代码导致CPU过高**

首先使用 `printf "%x\n" 线程号`，将线程号转换为16进制。

然后使用 `jstack 进程号 | grep 线程号16进制表示 -C5 --color` 使用 jstack 打印进程的堆栈信息，然后通过 grep 哪个线程的16进制的pid，找到那个线程相关的东西，这个时候就可以在打印出的信息中看到是哪个类的哪个方法导致的这个 CPU 100%的问题。

### ==2.线上进程 kill 不掉怎么办？==

进程 kill 不掉是因为该进程是由父进程创建的子进程，但是该进程变为了僵尸进程，就是进入到了 zombie 状态。这是因为这个进程释放了资源，但是没有得到父进程的确认。

处理如下：

`ps aux` 查看 STAT 那一栏，如果是 z，就是 zombie 状态的僵尸进程。

`ps aux | grep 僵尸进程id`，可以找到父进程id

然后先 kill 掉父进程即可。

### ==3.服务器存储空间快满了，在不影响服务正常运行的情况下该如何解决？==

首先 `df -h` 先看磁盘使用的情况。看看是不是日志文件过多，然后使用脚本删除比较旧的日志。

然后使用` find / -size+100M | xargs ls -lh` 找找是否有大于100M的大文件。

或者使用 `du -h > fs_du.log` 看看各个目录占用的磁盘所占用的磁盘空间大小，看看是不是有哪个目录有大量的小文件。

