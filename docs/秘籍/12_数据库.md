# 数据库

## SQL

#### 1.数据库的三级模式？

- 外模式
- 模式
- 内模式

![6](/Users/wx/project/interview/docs/秘籍/images/6.png)

#### 2.数据库中的锁？

**共享锁【S锁、读锁】**
若事务T对数据对象A加上S锁，则事务T**可以读A但不能修改A**，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S 锁之前不能对A做任何修改。

**排他锁【X锁、写锁】**
若事务T对数据对象A加上X锁，事务T**可以读A也可以修改A**，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。

#### 3.乐观锁&悲观锁

**1）乐观锁**

总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用**版本号机制**和**CAS算法**实现。

**乐观锁适用于多读的应用类型，这样可以提高吞吐量**，像数据库提供的类似于**write_condition机制**，其实都是提供的乐观锁。

**2）悲观锁**

总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

**3）总结**

**乐观锁适用于写比较少的情况下（多读场景）**，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以**一般多写的场景下用悲观锁就比较合适，多读情况下用乐观锁。**

#### 5.分布式事务&CAP理论

**在分布式系统中一次操作由多个系统协同完成，这种一次事务操作涉及多个系统通过网络协同完成的过程称为分布式事务**。这里强调的是多个系统通过网络协同完成一个事务的过程，并不强调多个系统访问了不同的数据库，即使多个系统访问的是同一个数据库也是分布式事务。

**CAP理论**是分布式事务处理的理论基础，了解了CAP理论有助于我们研究分布式事务的处理方案。

CAP理论是：分布式系统在设计时只能在**一致性(Consistency)、可用性(Availability)、分区容忍性(Partition Tolerance)中满足两种，无法兼顾三种**。

- **一致性(Consistency)**：服务A、B、C三个结点都存储了用户数据， 三个结点的数据需要保持同一时刻数据一致性。 
- **可用性(Availability)**：服务A、B、C三个结点，其中一个结点宕机不影响整个集群对外提供服务，如果只有服务A结点，当服务A宕机整个系统将无法提供服务，增加服务B、C是为了保证系统的可用性。 
- **分区容忍性(Partition Tolerance)**：分区容忍性就是允许系统通过网络协同工作，分区容忍性要解决由于网络分区导致数据的不完整及无法访问等问题。

分布式系统不可避免的出现了多个系统通过网络协同工作的场景，结点之间难免会出现网络中断、网延延迟等现象，这种现象一旦出现就导致数据被分散在不同的结点上，这就是网络分区。

分布式系统能否兼顾C、A、P？ 

在保证分区容忍性的前提下一致性和可用性无法兼顾，如果要提高系统的可用性就要增加多个结点，如果要保证数 据的一致性就要实现每个结点的数据一致，结点越多可用性越好，但是数据一致性越差。 所以，在进行分布式系统设计时，同时满足“一致性”、“可用性”和“分区容忍性”三者是几乎不可能的。

CAP有哪些组合方式？ 

1、CA：放弃分区容忍性，加强一致性和可用性，关系数据库按照CA进行设计。 

2、AP：放弃一致性，加强可用性和分区容忍性，追求最终一致性，很多NoSQL数据库按照AP进行设计。 

说明：这里放弃一致性是指放弃强一致性，强一致性就是写入成功立刻要查询出最新数据。追求最终一致性是指允许暂时的数据不一致，只要最终在用户接受的时间内数据一致即可。 

3、CP：放弃可用性，加强一致性和分区容忍性，一些强一致性要求的系统按CP进行设计，比如跨行转账，一次转账请求要等待双方银行系统都完成整个事务才算完成。 

说明：由于网络问题的存在CP系统可能会出现待等待超时，如果没有处理超时问题则整理系统会出现阻塞。

总结：

在分布式系统设计中**AP**的应用较多，即**保证分区容忍性和可用性，牺牲数据的强一致性（写操作后立刻读取到最新数据），保证数据最终一致性**。比如：订单退款，今日退款成功，明日账户到账，只要在预定的用户可以接受的 时间内退款事务走完即可。

## MySQL

mysql最基本的使用知识点：存储引擎（简单了解）、索引（能建索引，写的sql能用上索引）、事务（了解事务的隔离级别，基于spring的事物支持在代码里加事务）、锁。

### ==1.Mysql都有哪些搜索引擎？MyISAM和InnoDB区别？==

常用的有MyISAM和InnoDB两种搜索引擎，目前主要使用的是 InnoDB。

存储引擎主要作用对象是**数据库的表**。

**1）MyISAM**

MyISAM是MySQL的默认数据库引擎（5.5版之前）。MyISAM不支持事务和行级锁，不支持外键约束，索引文件和数据文件分开，这样在内存里可以缓存更多的索引，对查询的性能更好，适用于那种少量的插入大量的查询的场景。经典的使用场景是报表系统。

**2）InnoDB**

5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。主要特点是支持事务，强制要求有主键，支持外键约束，支持分库分表，读写分离，主备切换。

**3）两者的对比**

1. **count运算上的区别**： 因为**MyISAM缓存有表meta-data**（行数等），因此在做**COUNT(*)**时-对于一个结构很好的查询是不需要消耗多少资源的。而对于InnoDB来说，则没有这种缓存
2. **是否支持事务和崩溃后的安全恢复**： MyISAM 强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持；但是 InnoDB 提供事务支持事务，外部键等高级数据库功能。 具有事务 (commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。
3. **是否支持外键**： MyISAM不支持，而InnoDB支持。
4. **锁**：MyISAM只支持表级锁；InnoDB支持表级锁和行级锁。

**4）两者的总结**

MyISAM更适合**读密集**的表，而InnoDB更适合**写密集**的的表。

一般来说，如果需要事务支持，并且有较高的并发读取频率(MyISAM的表锁的粒度太大，所以当该表写并发量较高时，要等待的查询就会很多了)，InnoDB是不错的选择。如果你的数据量很大（MyISAM支持压缩特性可以减少磁盘 的空间占用），而且不需要支持事务时，MyISAM是最好的选择。

### ==2.什么是事务？==

**事务是逻辑上的一组操作，要么都执行，要么都不执行。**事物的四大特性(ACID)：

- **原子性（Atomicity）：** 语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于**undo log**；
- **一致性（Consistency）：** 事务追求的最终目标，一致性的实现既需要数据库层面的保障，也需要应用层面的保障；
- **隔离性（Isolation）：** 保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是**RR**，**RR**的实现主要基**于锁机制（包含next-key lock）**、**MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）**；
- **持久性（Durability）：** 保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于**redo log**。



首先介绍一下MySQL的事务日志。MySQL的日志有很多种，如**二进制日志、错误日志、查询日志、慢查询日志**等，此外 **InnoDB**存储引擎还提供了两种事务日志：

- **redo log(重做日志)**：用于保证事务持久性；

- **undo log(回滚日志)**：是事务原子性和隔离性实现的基础。

下面说回 **undo log**。实现原子性的关键，是当事务**回滚**时能够撤销所有已经成功执行的sql语句。**InnoDB**实现回滚，靠的是**undo log**：当事务对数据库进行修改时，**InnoDB**会生成对应的**undo log**；如果事务执行失败或调用了**rollback**，导致事务需要回滚，便可以利用**undo log**中的信息将数据回滚到修改之前的样子。

**undo log**属于**逻辑日志**，它记录的是sql执行相关的信息。当发生回滚时，**InnoDB**会根据**undo log**的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。以update操作为例：当事务执行update时，其生成的undo log中会包含被修改行的主键(以便知道修改了哪些行)、修改了哪些列、这些列在修改前后的值等信息，回滚时便可以使用这些信息将数据还原到update之前的状态。



**redo log**和**undo log**都属于**InnoDB**的事务日志。下面先聊一下**redo log**存在的背景。

**InnoDB**作为MySQL的存储引擎，数据是存放在**磁盘**中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，**InnoDB**提供了**缓存(Buffer Pool)**，**Buffer Pool**中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从**Buffer Pool**中读取，如果**Buffer Pool**中没有，则从**磁盘**读取后放入**Buffer Pool**；当向数据库写入数据时，会首先写入**Buffer Pool**，**Buffer Pool**中修改的数据会**定期**刷新到磁盘中（这一过程称为**刷脏**）。

**Buffer Pool**的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时**Buffer Pool**中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的**持久性**无法保证。

于是，**redo log**被引入来解决这个问题：当数据修改时，除了修改**Buffer Pool**中的数据，还会在**redo log**记录这次操作；当事务**提交**时，会调用 **fsync** 接口对 **redo log** 进行**刷盘**。如果MySQL宕机，重启时可以读取 **redo log** 中的数据，对数据库进行恢复。**redo log**采用的是 **WAL（Write-ahead logging，预写式日志**），所有修改**先写入日志，再更新到Buffer Pool**，保证了数据不会因MySQL宕机而丢失，从而满足了**持久性**要求。

既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？主要有以下两方面的原因：

（1）刷脏是**随机IO**，因为每次修改的数据**位置随机**，但写redo log是**追加操作**，属于**顺序IO**。

（2）刷脏是以**数据页（Page）**为单位的，MySQL默认页大小是**16KB**，一个Page上一个小修改都要**整页写入**；而redo log中只包含真正**需要写入的部分**，无效IO大大减少。

### ==3.并发事务带来哪些问题?==

在典型的应用程序中，多个**事务并发运行**，经常会操作相同的数据来完成各自的任务。并发虽然是必须的，但可能会导致以下的问题：

- **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
- **丢失修改（Lost to modify）:** 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。
- **不可重复读（Unrepeatableread）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
- **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

这些问题都是由于**事务并行**运行结果。

### ==4.事务隔离级别有哪些?MySQL的默认隔离级别是?底层实现原理==

SQL 标准定义了四个**隔离级别：**

- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
- **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，多次重复读的数据不一致。**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

| 隔离级别         | 脏读 | 不可重复读 | 幻读 |
| ---------------- | ---- | ---------- | ---- |
| READ-UNCOMMITTED | √    | √          | √    |
| READ-COMMITTED   | ×    | √          | √    |
| REPEATABLE-READ  | ×    | ×          | √    |
| SERIALIZABLE     | ×    | ×          | ×    |

MySQL InnoDB 存储引擎的**默认支持**的隔离级别是 **REPEATABLE-READ（可重读）**。也就是说每个事务都会开启一个自己要操作的某个数据的**快照**，事务期间，读到的都是这个数据的快照罢了，对一个数据的多次读取结果都是一样的。

InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下使用的是 **Next-Key Lock** （表级锁+行级锁组合，record+gap 锁定一个范围，包含记录本身）锁算法，因此可以避免幻读的产生。所以说InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 **SERIALIZABLE(可串行化)** 隔离级别。

Mysql的 REPEATABLE-READ 是通过**MVCC机制**（多版本并发控制机制）来实现的。

具体来说：

innodb存储引擎会在每行数据的最后添加**两个隐藏列**，一个**保存该行的创建时间**，一个**保存该行的删除时间**。但是这里保存的不是时间，而是**事务id**，事务id是 mysql 自己维护的**自增全局唯一**的id。

在一个事务查询的时候，mysql查询**创建时间的事务id小于等于当前事务id**的行，同时会查询**删除时间的事务id未定义或者大于当前事务id**的行，这样就可以确保这个行是在当前事务中或者之前创建的。只要满足这两个条件的数据都会被读出来。

然后假如在事务的执行期间别的事务更新了一条数据呢？

那么在innodb中会被插入一条记录，新插入的记录的创建时间设置为新的事物的id，同时将这条记录之前的那个版本的删除时间设置为新的事务的id。

这样就保证事务对数据的查询始终都是查找之前的那个**快照数据**，因为之前的那个快照的创建时间小于等于自己的事务id，然后删除时间的事务id比自己的事务id大。所以这个事务在运行期间会一直读取到这条数据的同一个版本。

### ==5.数据库锁有哪些类型？==

- **表锁**：一般 myisam 会加表锁，就是在 myisam 引擎下执行查询的时候会默认加个**表共享锁**，也就是表读锁，此时别人来就只能来查，不能写数据；然后 myisam 写数据的时候，也会加个**表独占锁**，也就是表写锁，别人不能读也不能写。innodb也有表锁，分为**意向共享锁、意向排他锁**，innodb会自动添加表锁，无需自己去加。
- **行锁**：一般 innodb 会加行锁，innodb 的行锁有**共享锁（s锁）**和**排他锁（x锁）**。
  - 共享锁就是**多个事务都可以加共享锁读同一行数据，但是别的事务不能写这行数据**；
  - 排他锁就是**一个事务可以写这行数据，别的事务只能读不能写**。
  - **insert、update、delete**操作innodb会自动给那一行加排他锁。
  - **select是不加锁的，因为是直接读取快照**。

### ==6.悲观锁和乐观锁是什么？使用场景是什么？==

- **悲观锁**总是认为会出现问题，在对数据处理时直接加锁。
- **乐观锁**认为差不多可以获得锁，不需要提前加锁。可以通过**版本号机制**来控制。

### ==7.mysql死锁原理以及是如何定位和解决？==

锁资源的抢占导致出现死锁现象。也就是分别持有了锁还去获取其他事务持有的锁就会导致出现死锁。

查看对应的**死锁日志**，然后根据对应的sql来寻找对应的代码来进行处理。

### ==8.Mysql调优的常用手段（查询优化）==

优化的思路：

- **设计数据库**时：数据库表、字段的设计，存储引擎
- 利用好MySQL自身提供的功能，如**索引**等
- **横向扩展**：MySQL集群、负载均衡、读写分离
- **SQL语句的优化**（收效甚微）

[MySQL优化/面试，看这一篇就够了](https://juejin.im/post/6844903750839058446)

首先可以通过阅读 sql 的**执行计划**来看当前导致性能变慢的因素：

```sql
explain select * from table
```

一般会针对查询是全表查询的属性列添加相应的**索引**。

当MySQL**单表记录数过大**时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：

1、**限定数据的范围**

务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；

2、**读/写分离**

经典的数据库拆分方案，**主库负责写，从库负责读**；

3、**垂直分区**

**根据数据库里面数据表的相关性进行拆分。** 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

**简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。** 

- **垂直拆分的优点：** 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。
- **垂直拆分的缺点：** 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

4、**水平分区**

**保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。**

水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。

水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 **水平拆分最好分库** 。

水平拆分能够 **支持非常大的数据量存储，应用端改造也少**，但 **分片事务难以解决** ，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 **尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度** ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

**下面补充一下数据库分片的两种常见方案：**

- **客户端代理：** **分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。** 当当网的 **Sharding-JDBC** 、阿里的TDDL是两种比较常用的实现。
- **中间件代理：** **在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。** 我们现在谈的 **Mycat** 、360的Atlas、网易的DDB等等都是这种架构的实现。

### ==9.解释一下什么是池化设计思想。什么是数据库连接池?为什么需要数据库连接池?==

池化设计应该不是一个新名词。我们常见的如java线程池、jdbc连接池、redis连接池等就是这类设计的代表实现。这种设计会**初始预设资源**，解决的问题就是抵消每次获取资源的消耗，如创建线程的开销，获取远程连接的开销等。

除了初始化资源，池化设计还包括如下这些特征：**池子的初始值、池子的活跃值、池子的最大值**等，这些特征可以直接映射到java线程池和数据库连接池的成员属性中。

数据库连接本质就是**一个 socket 的连接**。数据库服务端还要维护一些缓存和用户权限信息之类的所以占用了一些内存。我们可以把数据库连接池是看做是维护的数据库连接的缓存，以便将来需要对数据库的请求时可以重用这些连接。为每个用户打开和维护数据库连接，尤其是对动态数据库驱动的网站应用程序的请求，既昂贵又浪费资源。

**在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。如果使用了所有连接，则会建立一个新连接并将其添加到池中**。

### ==10.Mysql索引？索引的原理？B+树和B-树的区别？聚簇索引和非聚簇索引？索引的使用规则？索引的使用注意事项？==

索引是帮助 Mysql 高效获取数据的**排好序**的**数据结构**。

Mysql中支持的索引（从逻辑的角度来说）：

- **主键索引**：主键索引是一种特殊的唯一索引，不允许有空值。
- **唯一索引**：索引的值唯一。
- **普通索引**：单列索引。
- **联合索引**：联合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用联合索引时遵循**最左前缀匹配原则**。
- **空间索引**：空间索引是对空间数据类型的字段建立的索引。

**1）索引的数据结构**

mysql的索引的数据结构是：B+树，也可以是hash表，但不常用。

为什么使用B+树：

B/B+树是为了**磁盘**或其它存储设备而设计的一种**平衡多路查找树**(相对于二叉，B树每个内节点有多个分支)，与红黑树相比，在相同的的节点的情况下，一颗B/B+树的高度远远小于红黑树的**高度**。B/B+树上操作的时间通常由**存取磁盘的时间和CPU计算时间**这两部分构成，而CPU的速度非常快，所以B树的操作效率取决于**访问磁盘的次数**，关键字总数相同的情况下B树的高度越小，**磁盘I/O**所花的时间越少。

B树在提高了IO性能的同时并没有解决**元素遍历效率低下**的问题，正是为了解决这个问题，B+树应用而生。

B+树只需要去**遍历叶子节点就可以实现整棵树的遍历**。而且在数据库中**基于范围的查询**是非常频繁的，而B树不支持这样的操作或者说效率太低。

一颗传统的 M 阶 B+ 树需要满足以下几个要求：

- 从根节点到叶节点的**所有路径**都具有**相同的**长度。
- 所有**数据信息都存储在叶子节点**，非叶子节点仅作为叶节点的**索引**存在。
- 是一个平衡多叉树。

**在B+树中，所有记录的节点按大小顺序存放在同一层的叶节点中，各叶子节点用双向指针进行连接。**

B+树中存储的是**页**结构，在Mysql中默认的页面大小是**16Kb**，其中B+树叶子节点中存储的页面结构为：

- **页头**：包含对应的头指针和尾指针。
- **页目录**：页目录是一个**数组**，将具体的数据分组，默认每6个元素为一组，数组保存每组的头指针的位置。
- **用户数据区域**：以链表的形式保存用户存入的数据，按照顺序进行排序。

**2）B+树和B树的区别？**

B+树和B树都是**平衡多叉搜索树**。

B-树将数据存储在节点中；B+树将数据存储在叶子节点中。

**3）聚簇索引和非聚簇索引**

聚簇索引和非聚簇索引是指索引在**物理**上的保存形式来决定的。**聚簇索引是指索引和索引文件一起保存，非聚簇索引是指索引和索引文件分开保存**。

MySQL 默认的存储引擎 InnoDB 会使用 B+ 树来存储数据。对于 InnoDB 来说，所有的数据都是以**键值对**的方式存储的，主键索引和辅助索引在存储数据时会将 `id` 和 `index` 作为键，将所有列和 `id` 作为键对应的值。

innodb要求必须要有主键，主键作为索引，而主键对应的行就作为索引文件保存在叶子节点中，这种索引称为**聚簇索引**，索引文件和索引是在一起的。

非主键列上的索引中保存的是对应的主键信息，然后通过主键再来查询对应的数据，这样是为了**保持一致性并且节约索引空间**。

而**非聚簇索引**是指索引和索引文件分开保存，这种是MyISAM中使用到的索引结构。

因此不建议使用uuid来作为主键，这样会导致索引过大，浪费空间。建议使用 auto_increment 自增值来作为主键值。

**4）索引的使用规则**

一般来说要根据平时查询的数据建立一个**联合索引**，为了使用**联合索引**就必须得遵守下面的索引使用原则（重要就是掌握**最左前缀匹配原则**）

- **全列匹配**：在创建了索引的多个列上设置查询条件是可以使用上索引的。
- **最左前缀匹配原则**：在查询语句中使用到了联合索引最左边的一个或者几个列，也是可以使用到这个索引的。
- **最左前缀匹配了，但是中间某个值没有匹配**：假如联合索引有三列，但是只匹配到了第一列和第三列，那么会首先按照第一列从索引中去查找数据，然后在根据第三列的条件对结果进行过滤。但是第三列是不走索引的，就是有一个额外的过滤过程，但还是能够用到索引。
- **没有最左前缀匹配**：那就不能使用到索引了。
- **like操作**：like操作来查询数据必须将 % 放在后面，也就是 like 的数据最左边必须是确定的才可以用上索引。
- **范围列匹配**：如果是范围查询，比如 >=,<=,between 等操作，只有最左前缀的规则才可以使用索引进行范围查询，之后的就不能使用索引了。
- **包含函数**：如果某个列包含函数，那么就不会使用索引了。

最左前缀匹配原则的底层实现原理是跟底层的**索引数据结构**有关的。联合索引的底层数据结构也是**B+树**，只不过创建这颗b+树是通过多个列的值来进行判断的，判断的依据是按照联合索引列的顺序按照第一个列开始往后走的顺序来进行比较的。假如第一个列就已经可以比较出来大小关系就直接进行b+树的创建，而第一个列相等的话就得需要用到后面的列的值。因为联合索引的索引树是按照最左列进行创建的也就导致想要在查询的过程中使用到对应的索引就必须得按照最左前缀匹配原则来进行。

**5）索引的缺点以及使用注意**

1、索引是有缺点的，比较常见的是会增加**磁盘消耗**。同时**高并发**的时候**频繁插入和修改索引**也会导致**性能损耗**。因此建议尽量创建少的索引，一个表创建一两个索引。

2、创建索引的时候要注意一个**选择性**的问题：select count(discount(col))/count(*),就可以看到选择性，就是这个列的唯一值在总行数的占比，如果过低就没有必要添加对应的索引了。（也就是数据中重复的元素的占比较低）

总的来说，sql要越简单越好，基本都是单表CRUD。复杂的逻辑都是通过 java 代码来实现的。sql只是用来存储的，不是用来计算的。 

**6）Mysql为什么要设置主键？**

因为设置主键之后可以方便Mysql按照主键对数据进行维护，通过主键来维护为一个对应的B+树结构。

假如不设置主键的话，mysql会从第一列开始寻找一个合适的列（该列数据不存在重复，即保证唯一性）来将其作为“主键”来构建对应的B+树机构，假如找不到的话就自动创建一个具有唯一性的**隐藏列**。这样会给mysql增加额外的负担。

**7）为什么主键推荐设置为整形自增的？**

主键设置为整形是方便在建立和查找索引的过程中进行索引值的比较，相比较于 uuid 等主键来说整形索引进行比较的效率更高；另一方面也是为了保证在b+树中存储更多的索引信息，因为长整形数据也只会占据8kb的大小，相比较于字符串来说占空间较小。

主键设置为**自增**的是为了方便在建立索引b+树的时候可以减少树的**分裂次数**，假如不是自增的会导致在创建索引树的时候造成b+树的分裂。

**8）多个单列索引**

多个单列索引在**多条件查询**时优化器会选择**最优索引选择策略**，可能只用一个索引，也可能将多个索引全用上！ 但多个单列索引底层会建立多个B+索引树，比较占用空间，也会浪费一定搜索效率，故如果只有**多条件联合查询时最好建联合索引！**

**9）如何查看一个查询语句用到了索引**

**explain**显示了MySQL如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。简单讲，它的作用就是分析查询性能。

explain关键字的使用方法很简单，就是把它放在select查询语句的前面。

mysql查看是否使用索引，简单的看**type**类型就可以。如果它是all，那说明这条查询语句遍历了所有的行，并没有使用到索引。

### ==11.SQL 中left join、right join、inner join的区别？==

三个join的含义：

- **left join（左联接）**：返回**左表中的所有记录**以及和**右表中的联接字段相等**的记录。
- **right join（右联接）**：返回**右表中的所有记录**以及和**左表中的联接字段相等**的记录。
- **inner join（等值联接）**：只返回**两个表中联接字段相等**的记录。

join的底层实现：

https://zhuanlan.zhihu.com/p/54275505

### ==12.mysql锁总结==

https://zhuanlan.zhihu.com/p/29150809

