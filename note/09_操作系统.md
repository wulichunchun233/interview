# 操作系统

## 操作系统基础

### 1.系统调用（用户态如何切换到内核态？）

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

1. **用户态(user mode) **： 用户态运行的进程或可以直接读取用户程序的数据。
2. **系统态(kernel mode)**：可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类（用户态如何切换到内核态的方法）：

- 设备管理。完成设备的请求或释放，以及设备启动等功能。
- 文件管理。完成文件的读、写、创建及删除等功能。
- 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
- 进程通信。完成进程之间的消息传递或信号传递等功能。
- 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

### 2.为什么要分用户态和内核态？

简单以一句话是为了安全， 在CPU的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。

如果所有的程序都能使用这些指令，那么系统死机的概率将大大增加。

所以出于安全的考虑，CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令。

### 3.虚拟地址空间和物理地址空间的区别和联系？

所谓**地址空间**，是地址访问可以达到的所有地址的集合。

**物理地址空间**是实在的存在于计算机中的一个实体，也就是物理内存。

计算机上都存在一个程序能够产生的地址集合，我们称之为地址范围。这个范围的大小由CPU的位数决定，例如一个32位的CPU，它的地址范围是0~0xFFFFFFFF (4G),而对于一个64位的CPU，它的地址范围为0~0xFFFFFFFFFFFFFFFF (64T).这个范围就是我们的程序能够产生的地址范围，我们把这个地址范围称为**虚拟地址空间**，该空间中的某一个地址我们称之为虚拟地址。

与虚拟地址空间和虚拟地址相对应的则是**物理地址空间**和物理地址，大多数时候我们的系统所具备的物理地址空间只是虚拟地址空间的一个子集。

### 4.如何实现虚拟地址空间？

现代操作系统普遍采用虚拟内存管理（Virtual Memory Management）机制，这需要处理器中的MMU（Memory Management Unit，内存管理单元）提供支持。

从虚拟地址到物理地址的运行时映射是由内存管理单元（MMU）的硬件设备来完成。CPU 在访问内存的时候都需要通过 MMU 把虚拟地址转化为物理地址，然后通过总线访问内存。MMU 开启后 CPU 看到的所有地址都是虚拟地址，CPU 把这个虚拟地址发给 MMU 后，MMU 会通过页表在页表里查出这个虚拟地址对应的物理地址是什么，从而去访问外面的 DDR（内存条）。

MMU 是通过页表把虚拟地址转换成物理地址，页表是一种特殊的数据结构，放在系统空间的页表区存放逻辑页与物理页帧的对应关系，每一个进程都有一个自己的页表。

### 5.介绍下mmap的原理？

mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图所示：

![](https://images0.cnblogs.com/blog2015/571793/201507/200501092691998.png)

由上图可以看出，进程的虚拟地址空间，由多个虚拟内存区域构成。虚拟内存区域是进程的虚拟地址空间中的一个同质区间，即具有同样特性的连续地址范围。上图中所示的text数据段（代码段）、初始数据段、BSS数据段、堆、栈和内存映射，都是一个独立的虚拟内存区域。而为内存映射服务的地址空间处在堆栈之间的空余部分。

linux内核使用vm_area_struct结构来表示一个独立的虚拟内存区域，由于每个不同质的虚拟内存区域功能和内部机制都不同，因此一个进程使用多个vm_area_struct结构来分别表示不同类型的虚拟内存区域。各个vm_area_struct结构使用链表或者树形结构链接，方便进程快速访问，如下图所示：

![](https://images0.cnblogs.com/blog2015/571793/201507/200501434261629.png)

vm_area_struct结构中包含区域起始和终止地址以及其他相关信息，同时也包含一个vm_ops指针，其内部可引出所有针对这个区域可以使用的系统调用函数。这样，进程对某一虚拟内存区域的任何操作需要用要的信息，都可以从vm_area_struct中获得。mmap函数就是要创建一个新的vm_area_struct结构，并将其与文件的物理磁盘地址相连。

mmap内存映射的实现过程，总的来说可以分为三个阶段：

**（一）进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域**

1、进程在用户空间调用库函数mmap，原型：void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);

2、在当前进程的虚拟地址空间中，寻找一段空闲的满足要求的连续的虚拟地址

3、为此虚拟区分配一个vm_area_struct结构，接着对这个结构的各个域进行了初始化

4、将新建的虚拟区结构（vm_area_struct）插入进程的虚拟地址区域链表或树中

**（二）调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系**

5、为映射分配了新的虚拟地址区域后，通过待映射的文件指针，在文件描述符表中找到对应的文件描述符，通过文件描述符，链接到内核“已打开文件集”中该文件的文件结构体（struct file），每个文件结构体维护着和这个已打开文件相关各项信息。

6、通过该文件的文件结构体，链接到file_operations模块，调用内核函数mmap，其原型为：int mmap(struct file *filp, struct vm_area_struct *vma)，不同于用户空间库函数。

7、内核mmap函数通过虚拟文件系统inode模块定位到文件磁盘物理地址。

8、通过remap_pfn_range函数建立页表，即实现了文件地址和虚拟地址区域的映射关系。此时，这片虚拟地址并没有任何数据关联到主存中。

**（三）进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝**

注：前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。

9、进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常。

10、缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程。

11、调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中。

12、之后进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。

注：修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步, 这样所写的内容就能立即保存到文件里了。

### 6.虚拟内存

虚拟内存使得应用程序认为它拥有连续的可用内存，这样一来，就在逻辑层面上扩大了内存容量。但是实际上，只是把比较常用的内存片段取出来了而已，还有部分资源是放在磁盘存储器上的，需要的时候再进行页面调度。

调度方式有，分页式，段式，段页式。比较流行方式是段页式，他结合了前两者的优点，以页为单位替换，以段为单位使用。

常见的替换替换算法有4种，随机算法，先进先出算法，LRU算法，最优算法。 比较常使用的是LRU算法，他在redis里也有使用，当redis的内存满了的时候就是使用LRU算法替换掉旧内存。

### 7.读取文件的流程？

**读文件**

1、进程调用库函数向**内核**发起读文件请求；

2、**内核**通过检查进程的**文件描述符**定位到**虚拟文件系统**的已打开**文件列表表项**；

3、调用该文件可用的系统调用函数**read()**

3、**read()**函数通过**文件表项**链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的**inode**；

4、在**inode**中，通过文件内容偏移量计算出要读取的页；

5、通过**inode**找到文件对应的**address_space**；

6、在**address_space**中访问该文件的**页缓存树**，查找对应的页缓存结点：

（1）如果页缓存命中，那么直接返回文件内容；

（2）如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页；重新进行第6步查找页缓存；

7、文件内容读取成功。

**写文件**

前5步和读文件一致，在address_space中查询对应页的页缓存是否存在：

6、如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去。

7、如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页。此时缓存页命中，进行第6步。

8、一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块。有两种方式可以把脏页写回磁盘：

（1）手动调用sync()或者fsync()系统调用把脏页写回

（2）pdflush进程会定时把脏页写回到磁盘

同时注意，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放。

### ==8.内存中的堆栈==

**堆栈：一种数据结构，一个在程序运行时用于存放的地方**

在数据结构中，**栈**是一种可以实现“先进后出”（或者称为“后进先出”）的存储结构；相对于栈的“先进后出”特性，**堆**则是一种经过排序的树形数据结构，常用来实现优先队列等，堆是一种特殊的完全二叉树。其中，节点是从左到右填满的，并且最后一层的树叶都在最左边（即如果一个节点没有左儿子，那么它一定没有右儿子）；每个节点的值都小于（或者都大于）其子节点的值。

在 C 语言中，内存分配方式不外乎有如下三种形式：

1. 从静态存储区域分配：它是由编译器自动分配和释放的，即内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在，直到整个程序运行结束时才被释放，如全局变量与 static 变量。
2. 在**栈**上分配：它同样也是由编译器自动分配和释放的，即在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元将被自动释放。需要注意的是，栈内存分配运算内置于处理器的指令集中，它的运行效率一般很高，但是分配的内存容量有限。
3. 从**堆**上分配：也被称为动态内存分配，它是由程序员手动完成申请和释放的。即程序在运行的时候由程序员使用内存分配函数（如 malloc 函数）来申请任意多少的内存，使用完之后再由程序员自己负责使用内存释放函数（如 free 函数）来释放内存。也就是说，动态内存的整个生存期是由程序员自己决定的，使用非常灵活。需要注意的是，如果在堆上分配了内存空间，就必须及时释放它，否则将会导致运行的程序出现内存泄漏等错误。

栈内存是**由编译器自动分配与释放**的，它有两种分配方式：**静态分配**和**动态分配**。

- 静态分配是由**编译器**自动完成的，如**局部变量**的分配（即在一个函数中声明一个 int 类型的变量i时，编译器就会自动开辟一块内存以存放变量 i）。与此同时，其生存周期也只在函数的运行过程中，在运行后就释放，并不可以再次访问。
- 动态分配由 **alloca 函数**进行分配，但是栈的动态分配与堆是不同的，它的动态分配是由编译器进行释放，无需任何手工实现。值得注意的是，虽然用 alloca 函数可以实现栈内存的动态分配，但 alloca 函数的可移植性很差，而且在没有传统堆栈的机器上很难实现。因此，不宜使用于广泛移植的程序中。当然，完全可以使用 C99 中的变长数组来替代 alloca 函数。

而堆内存则不相同，它完全是由程序员手动申请与释放的，程序在运行的时候由程序员使用内存分配函数（如 malloc 函数）来申请任意多少的内存，使用完再由程序员自己负责使用内存释放函数（如 free 函数）释放内存。

对栈而言，一般用于存放**函数的参数与局部变量**等；**对堆而言，具体存储内容由程序员根据需要决定存储数据。**

## 进程和线程

### ==1.进程和线程的区别？==

一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的 **程序计数器**、**虚拟机栈** 和 **本地方法栈**。

线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。

线程和进程最大的不同在于基本上**各进程是独立的**，而各线程则不一定，因为同一进程中的**线程极有可能会相互影响**。

线程执行开销小，但不利于资源的管理和保护；而进程正相反。

### ==2.IO多路复用==

**IO多路复用**是一种**同步IO模型**，实现一个**线程**可以监视多个**文件句柄**；一旦某个文件句柄**就绪**，就能够通知**应用程序**进行相应的**读写操作**；没有文件句柄就绪时会**阻塞应用程序**，交出cpu。**多路**是指**网络连接**，**复用**指的是**同一个线程**。

服务器端采用**单线程**通过**select/epoll**等**系统调用**获取**fd列表**，遍历**有事件的fd**进行**accept/recv/send**，使其能支持更多的并发连接请求。

与多进程和多线程技术相比，I/O多路复用技术的最大优势是**系统开销小**，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。

目前支持I/O多路复用的系统调用有 **select，poll，epoll**。

select/poll/epoll之间的区别：

|            | select             | poll             | epoll                                             |
| :--------- | :----------------- | :--------------- | :------------------------------------------------ |
| 数据结构   | **bitmap**         | 数组             | **红黑树**                                        |
| 最大连接数 | 1024               | 无上限           | 无上限                                            |
| fd拷贝     | 每次调用select拷贝 | 每次调用poll拷贝 | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 工作效率   | 轮询：O(n)         | 轮询：O(n)       | 回调：O(1)                                        |

**select**

select只有一个函数，调用select时，需要将监听句柄和最大等待时间作为参数传递进去，select会发生阻塞，直到一个事件发生了，或者等到最大1秒钟(tv定义了这个时间长度）就返回。

**缺点**

- select返回后要挨个遍历fd，找到被“SET”的那些进行处理
- select是无状态的，即**每次调用select，内核都要重新检查所有被注册的fd的状态**。select返回后，这些状态就被返回了，内核不会记住它们；到了下一次调用，内核依然要重新检查一遍。于是查询的效率很低
- select能够支持的最大的fd数组的长度是1024

**poll**

poll优化了select的一些问题，参数变得简单一些，没有了1024的限制。但其他的问题依旧。

**缺点**

- 依然是无状态的，性能的问题与select差不多一样
- 应用程序仍然无法很方便的拿到那些“有事件发生的fd“，还是需要遍历所有注册的fd

**epoll**

使用epoll时，需要先使用函数epoll_create()在内核层创建了一个数据表，接口参数是一个表达要监听事件列表的长度的数值（会动态改变的）。这样一来，不用每次监听都要传一遍fd（传递fd会导致fd数据从用户态复制到内核态）。

创建完数据表，就可以使用另外一个函数epoll_ctl()来管理数据表，对监听的fd执行增删改操作。

最后再调用epoll_wait()方法等待事件的发生。

**优点**

- 为什么epoll的性能比select和poll要强呢？ select和poll每次都需要把完成的fd列表传入到内核，迫使内核每次必须从头扫描到尾。而epoll完全是反过来的。epoll在内核的数据被建立好了之后，每次某个被监听的fd一旦有事件发生，内核就直接标记之。epoll_wait调用时，会尝试直接读取到当时已经标记好的fd列表，如果没有就会进入等待状态。
- 同时，epoll_wait直接只返回了被触发的fd列表，这样上层应用写起来也轻松愉快，再也不用从大量注册的fd中筛选出有事件的fd了。

epoll除了性能优势，还有一个优点——同时支持**水平触发(Level Trigger)**和**边沿触发(Edge Trigger)**。

- **水平触发**只关心文件描述符中是否还有没完成处理的数据，如果有，不管怎样epoll_wait，总是会被返回。简单说——**水平触发代表了一种“状态”**。

- **边沿触发**只关心文件描述符是否有新的事件产生，如果有，则返回；如果返回过一次，不管程序是否处理了，只要没有新的事件产生，epoll_wait不会再认为这个fd被“触发”了。简单说——**边沿触发代表了一个“事件”**。

考虑下图中的例子。有两个socket的fd——fd1和fd2。我们设定监听f1的“水平触发读事件“，监听fd2的”边沿触发读事件“。我们使用在时刻t1，使用epoll_wait监听他们的事件。在时刻t2时，两个fd都到了100bytes数据，于是在时刻t3, epoll_wait返回了两个fd进行处理。在t4，我们故意不读取所有的数据出来，只各自读50bytes。然后在t5重新注册两个事件并监听。在t6时，只有fd1会返回，因为fd1里的数据没有读完，仍然处于“被触发”状态；而fd2不会被返回，因为没有新数据到达。

![](https://upload-images.jianshu.io/upload_images/5822893-bb31711e6617737d.png)

**Netty的 epoll transport使用 epoll edge-triggered 而 java的 nio 使用 level-triggered**。

### ==3.进程间通信的方式及其应用场景？==

**1. 管道/匿名管道(pipe)**

- 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。

- 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程);

- 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。

- 数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。

![](https://upload-images.jianshu.io/upload_images/1281379-05378521a7b41af4.png)

**管道的实质：**

- 管道的实质是一个**内核缓冲区**，进程以**先进先出**的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。
- 该缓冲区可以看做是一个循环队列，读和写的位置都是自动增长的，不能随意改变，一个数据只能被读一次，读出来以后在缓冲区就不复存在了。
- 当缓冲区读空或者写满时，有一定的规则控制相应的读进程或者写进程进入等待队列，当空的缓冲区有新数据写入或者满的缓冲区有数据读出来时，就唤醒等待队列中的进程继续读写。

**管道的局限：**

管道的主要局限性正体现在它的特点上：

- 只支持单向数据流；
- 只能用于具有亲缘关系的进程之间；
- 没有名字；
- 管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个页面大小）；
- 管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，比如多少字节算作一个消息（或命令、或记录）等等；

**2. 有名管道(FIFO)**

匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道(FIFO)。

有名管道不同于匿名管道之处在于它提供了一个**路径名**与之关联，**以有名管道的文件形式存在于文件系统中**，这样，**即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信**，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循**先进先出(first in first out)**,对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。**有名管道的名字存在于文件系统中，内容存放在内存中。**

**匿名管道和有名管道总结：**

（1）管道是特殊类型的文件，在满足先入先出的原则条件下可以进行读写，但不能进行定位读写。

（2）匿名管道是单向的，只能在有亲缘关系的进程间通信；有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

（3）**无名管道阻塞问题：**无名管道无需显示打开，创建时直接返回文件描述符，在读写时需要确定对方的存在，否则将退出。如果当前进程向无名管道的一端写数据，必须确定另一端有某一进程。如果写入无名管道的数据超过其最大值，写操作将阻塞，如果管道中没有数据，读操作将阻塞，如果管道发现另一端断开，将自动退出。

（4）**有名管道阻塞问题：**有名管道在打开时需要确实对方的存在，否则将阻塞。即以读方式打开某管道，在此之前必须一个进程以写方式打开管道，否则阻塞。此外，可以以读写（O_RDWR）模式打开有名管道，即当前进程读，当前进程写，不会阻塞。

**3. 信号(Signal)**

- 信号是Linux系统中用于**进程间互相通信或者操作**的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。
- 如果该进程当前并未处于执行状态，则该信号就有内核保存起来，知道该进程回复执行并传递给它为止。
- 如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。

**Linux系统中常用信号：**

（1）**SIGHUP：**用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。

（2）**SIGINT：**程序终止信号。程序运行过程中，按`Ctrl+C`键将产生该信号。

（3）**SIGQUIT：**程序退出信号。程序运行过程中，按`Ctrl+\\`键将产生该信号。

（4）**SIGBUS和SIGSEGV：**进程访问非法地址。

（5）**SIGFPE：**运算中出现致命错误，如除零操作、数据溢出等。

（6）**SIGKILL：**用户终止进程执行信号。shell下执行`kill -9`发送该信号。

（7）**SIGTERM：**结束进程信号。shell下执行`kill 进程pid`发送该信号。

（8）**SIGALRM：**定时器信号。

（9）**SIGCLD：**子进程退出信号。如果其父进程没有忽略该信号也没有处理该信号，则子进程退出后将形成僵尸进程。

**信号来源**

信号是软件层次上对**中断机制**的一种模拟，是一种**异步通信方式**，，信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件主要有两个来源：

- **硬件来源**：用户按键输入`Ctrl+C`退出、硬件异常如无效的存储访问等。
- **软件终止**：终止进程信号、其他进程调用kill函数、软件异常产生信号。

**信号生命周期和处理流程**

（1）信号被某个进程产生，并设置此信号传递的对象（一般为对应进程的pid），然后传递给操作系统；

（2）操作系统根据接收进程的设置（是否阻塞）而选择性的发送给接收者，如果接收者阻塞该信号（且该信号是可以阻塞的），操作系统将暂时保留该信号，而不传递，直到该进程解除了对此信号的阻塞（如果对应进程已经退出，则丢弃此信号），如果对应进程没有阻塞，操作系统将传递此信号。

（3）目的进程接收到此信号后，将根据当前进程对此信号设置的预处理方式，暂时终止当前代码的执行，保护上下文（主要包括临时寄存器数据，当前程序位置以及当前CPU的状态）、转而执行中断服务程序，执行完成后在回复到中断的位置。当然，对于抢占式内核，在中断返回时还将引发新的调度。

![](https://upload-images.jianshu.io/upload_images/1281379-3eed8cca67aa9f55.png)

**4. 消息(Message)队列**

- 消息队列是存放在内核中的**消息链表**，每个消息队列由消息队列标识符表示。
- 与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
- 另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达

**消息队列特点总结：**

（1）消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识.

（2）消息队列允许一个或多个进程向它写入与读取消息.

（3）管道和消息队列的通信数据都是先进先出的原则。

（4）消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。

（5）消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。

（6）目前主要有两种类型的消息队列：POSIX消息队列以及System V消息队列，系统V消息队列目前被大量使用。系统V消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。

**5. 共享内存(share memory)**

- 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。
- 为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
- 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。

![](https://upload-images.jianshu.io/upload_images/1281379-adfde0d80334c1f8.png)

**6. 信号量(semaphore)**

信号量是一个**计数器**，用于多进程对共享数据的访问，信号量的意图在于**进程间同步**。

 为了获得共享资源，进程需要执行下列操作：

（1）**创建一个信号量**：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。

（2）**等待一个信号量**：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。

（3）**挂出一个信号量**：该操作将信号量的值加1，也称为V操作。

为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。Linux环境中，有三种类型：**Posix（[可移植性操作系统接口](https://link.jianshu.com?t=http://baike.baidu.com/link?url=hYEo6ngm9MlqsQHT3h28baIDxEooeSPX6wr_FdGF-F8mf7wDp2xJWIDtQWGEDxthtPNiJtlsw460g1_N0txJYa)）有名信号量（使用Posix IPC名字标识）**、**Posix基于内存的信号量（存放在共享内存区中）**、**System V信号量（在内核中维护）**。这三种信号量都可用于进程间或线程间的同步。

![](https://upload-images.jianshu.io/upload_images/1281379-376528c40d03717e.png)

![](https://upload-images.jianshu.io/upload_images/1281379-a72c8fbe22340031.png)

![](https://upload-images.jianshu.io/upload_images/1281379-a1b276fae9db985d.png)

> **信号量与普通整型变量的区别：**
>
> （1）信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait(semap) , signal(semap) ; 来进行访问；
>
> （2）操作也被成为PV原语（P来源于荷兰语proberen"测试"，V来源于荷兰语verhogen"增加"，P表示通过的意思，V表示释放的意思），而普通整型变量则可以在任何语句块中被访问；

> **信号量与互斥量之间的区别：**
>
> （1）互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。
>
> **互斥：**是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。
>
> **同步：**是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。
>
> 在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源
>
> （2）互斥量值只能为0/1，信号量值可以为非负整数。
>
> 也就是说，一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题。信号量可以实现多个同类资源的多线程互斥和同步。当信号量为单值信号量是，也可以完成一个资源的互斥访问。
>
> （3）互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。

**7. 套接字(socket)**

套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。

![](https://upload-images.jianshu.io/upload_images/1281379-2db1deb0115ec4f2.png)

套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

**套接字特性**

套接字的特性由3个属性确定，它们分别是：域、端口号、协议类型。

**（1）套接字的域**

它指定套接字通信中使用的网络介质，最常见的套接字域有两种：

**一是AF_INET，它指的是Internet网络。**当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的IP地址和端口来指定一台联网机器上的某个特定服务，所以在使用socket作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。

**另一个域AF_UNIX，表示UNIX文件系统，**它就是文件输入/输出，而它的地址就是文件名。

**（2）套接字的端口号**

每一个基于TCP/IP网络通讯的程序(进程)都被赋予了唯一的端口和端口号，端口是一个信息缓冲区，用于保留Socket中的输入/输出信息，端口号是一个16位无符号整数，范围是0-65535，以区别主机上的每一个程序（端口号就像房屋中的房间号），低于256的端口号保留给标准应用程序，比如pop3的端口号就是110，每一个套接字都组合进了IP地址、端口，这样形成的整体就可以区别每一个套接字。

**（3）套接字协议类型**

 因特网提供三种通信机制:

 **一是流套接字，**流套接字在域中通过TCP/IP连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。

 **二个是数据报套接字，**它不需要建立连接和维持一个连接，它们在域中通常是通过UDP/IP协议实现的。它对可以发送的数据的长度有限制，数据报作为一个单独的网络消息被传输,它可能会丢失、复制或错乱到达，UDP不是一个可靠的协议，但是它的速度比较高，因为它并一需要总是要建立和维持一个连接。

 **三是原始套接字，**原始套接字允许对较低层次的协议直接访问，比如IP、 ICMP协议，它常用于检验新的协议实现，或者访问现有服务中配置的新设备，因为RAW SOCKET可以自如地控制Windows下的多种协议，能够对网络底层的传输机制进行控制，所以可以应用原始套接字来操纵网络层和传输层应用。比如，我们可以通过RAW SOCKET来接收发向本机的ICMP、IGMP协议包，或者接收TCP/IP栈不能够处理的IP包，也可以用来发送一些自定包头或自定协议的IP包。网络监听技术很大程度上依赖于SOCKET_RAW。

> **原始套接字与标准套接字的区别在于**：
>
> 原始套接字可以读写内核没有处理的IP数据包，而流套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数据。因此，如果要访问其他协议发送数据必须使用原始套接字。

![](https://upload-images.jianshu.io/upload_images/1281379-2575b81bbab6b67b.png)

**服务器端**

（1）首先服务器应用程序用系统调用socket来创建一个套接字，它是系统分配给该服务器进程的类似文件描述符的资源，它不能与其他的进程共享。

（2）然后，服务器进程会给套接字起个名字，我们使用系统调用bind来给套接字命名。然后服务器进程就开始等待客户连接到这个套接字。

（3）接下来，系统调用listen来创建一个队列并将其用于存放来自客户的进入连接。

（4）最后，服务器通过系统调用accept来接受客户的连接。它会创建一个与原有的命名套接不同的新套接字，这个套接字只用于与这个特定客户端进行通信，而命名套接字（即原先的套接字）则被保留下来继续处理来自其他客户的连接（建立客户端和服务端的用于通信的流，进行通信）。

**客户端**

（1）客户应用程序首先调用socket来创建一个未命名的套接字，然后将服务器的命名套接字作为一个地址来调用connect与服务器建立连接。

（2）一旦连接建立，我们就可以像使用底层的文件描述符那样用套接字来实现双向数据的通信（通过流进行数据传输）。

### ==4.线程间通信方法==

- **锁机制**：包括互斥锁、条件变量、读写锁
  - **互斥锁**提供了以排他方式防止数据结构被并发修改的方法。
  - **读写锁**允许多个线程同时读共享数据，而对写操作是互斥的。
  - **条件变量**可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- **信号量机制(Semaphore)**：包括无名线程信号量和命名线程信号量
- **信号机制(Signal)**：类似进程间的信号处理

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

### 5.进程的调度算法？

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。 

### 6.线程间如何切换？

一个进程的多个线程间切换的时候就涉及到了**上下文切换**。

简单来说，就是有一个**时间片算法**，cpu会给每个线程一个时间片来执行，时间片结束之后就保存这个线程的状态，然后切换到下一个线程去执行。这也就是多线程并发执行的原理，就是多个线程反复切换，每个线程在一个时间片里执行。

### ==7.死锁是什么？为什么会出现死锁？如何解决？==

死锁是多**线程**并发可能会遇到的一个问题。

**1）死锁是什么？**

当线程A持有独占锁a，并尝试去获取独占锁b的同时，线程B持有独占锁b，并尝试获取独占锁a的情况下，就会发生AB两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。

**2）死锁的发生条件**

- **互斥**：一个资源每次只能被一个线程使用。
- **循环等待**：若干线程之间形成一种头尾相接的循环等待资源关系。
- **请求保持**：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
- **不可剥夺**：线程已获得的资源，在未使用完之前，不能强行剥夺。

**3）如何解决死锁？**

破坏上面四个条件之一就可以解决死锁，使用的算法是**银行家算法**。

**银行家算法**：当一个进程申请使用资源的时候，银行家算法通过先 **试探** 分配给该进程资源，然后通过**安全性算法**判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。

![](https://img-blog.csdn.net/20180508204335770?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNDE0Mjcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



## Linux

### ==0.Linux常见命令==

```shell
# 进入文件目录
cd 文件目录

# 创建文件夹
mkdir 文件夹名

# 复制文件
cp 文件名 新文件名

# 移动以及重命名文件
mv 文件名 新文件名

# 删除文件
rm 文件名

# 查找文件
find 目录 参数

# 查找文件内容
grep 参数 正则表达式 文件名

# 修改文件
vi 文件名

# 更改文件权限
chmod a+x 文件名

# 列出当前正在运行的进程
ps aux

# 查看当前进程的运行状况
top

# 查看当前磁盘的情况
df

# 查看端口占用情况 lsof(list open files)
lsof -i:端口号
netstat -tnpl | grep 端口号
```

### ==2.Linux load averages含义？==

load average：操作系统的平均负荷，里面有三个数字，三个数字的意思分别是**1分钟、5分钟、15分钟**内系统的平均负荷，我们可以从中判断系统负荷是大还是小。

Linux load averages 是**系统负载**平均值（system load averages），它将正在运行的线程（任务）对系统的需求显示为平均运行数和等待线程数。Linux load averages 可以衡量任务对系统的需求，并且它可能大于系统当前正在处理的数量，大多数工具将其显示为三个平均值，分别为 1、5 和 15 分钟值。

一些解释：

- 如果平均值为 0.0，意味着系统处于空闲状态
- 如果 1min 平均值高于 5min 或 15min 平均值，则负载正在增加
- 如果 1min 平均值低于 5min 或 15min 平均值，则负载正在减少
- 如果它们高于系统 CPU 的数量，那么系统很可能会遇到性能问题（视情况而定）

Linux 中的 load average 已经从 “CPU load averages” 变为 “**system load averages**”。测量正在运行和等待运行的线程数（CPU，磁盘，不间断锁）。换句话说，它测量不完全空闲的线程数。优点：包含了对不同资源的需求。

在其他操作系统上，load averages 是 “**CPU load averages**”，测量 CPU 运行的数量 + CPU 可运行的线程。优点：更容易理解（仅适用于CPU）。

### ==3.系统内存占用情况==

linux下在终端环境下可以使用 **free** 命令看到系统实际使用内存的情况，一般用 **free -m** 方式查看内存占用情况（兆为单位）。

系统实际内存占用以及可用内存有如下几个加减法：

- **used=total-free** 即 **total=used+free**
- 实际内存占用：**used-buffers-cached** 即 **total-free-buffers-cached**
- 实际可用内存：**buffers+cached+free**

## 应用题

### ==1.线上服务器 CPU 100%该如何排查、定位和解决？==

**1）定位耗费CPU的进程**

`top -c`就可以显示进程列表，然后输入 `P`，按照 CPU 使用率来排序。这样就可以看到哪个进程的 CPU 负载最高。

**2）定位耗费CPU的线程**

`top -Hp 进程号`，然后输入 `P`，按照 CPU 的使用率排序。这样就可以看到这个进程里哪个线程耗费 CPU 最高。

**3）定位哪段代码导致CPU过高**

首先使用 `printf "%x\n" 线程号`，将线程号转换为16进制。

然后使用 `jstack 进程号 | grep 线程号16进制表示 -C5 --color` 使用 jstack 打印进程的堆栈信息，然后通过 grep 哪个线程的16进制的pid，找到那个线程相关的东西，这个时候就可以在打印出的信息中看到是哪个类的哪个方法导致的这个 CPU 100%的问题。

### ==2.线上进程 kill 不掉怎么办？==

进程 kill 不掉是因为该进程是由父进程创建的子进程，但是该进程变为了僵尸进程，就是进入到了 zombie 状态。这是因为这个进程释放了资源，但是没有得到父进程的确认。

处理如下：

`ps aux` 查看 STAT 那一栏，如果是 z，就是 zombie 状态的僵尸进程。

`ps aux | grep 僵尸进程id`，可以找到父进程id

然后先 kill 掉父进程即可。

### ==3.服务器存储空间快满了，在不影响服务正常运行的情况下该如何解决？==

首先 `df -h` 先看磁盘使用的情况。看看是不是日志文件过多，然后使用脚本删除比较旧的日志。

然后使用` find / -size+100M | xargs ls -lh` 找找是否有大于100M的大文件。

或者使用 `du -h > fs_du.log` 看看各个目录占用的磁盘所占用的磁盘空间大小，看看是不是有哪个目录有大量的小文件。

